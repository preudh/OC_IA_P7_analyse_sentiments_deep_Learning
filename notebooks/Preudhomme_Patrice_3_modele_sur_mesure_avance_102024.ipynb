{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Développement du \"Modèle sur mesure avancé\" avec des essais sur au moins deux word embeddings différents et en gardant celui qui permet d’obtenir les meilleures performances. Nous utiliserons Glove et FastText.\n",
    "-  Nous allons construire et entraîner un réseau de neurones pour chaque embedding, évaluer les performances et enregistrer les expérimentations avec MLFlow. \n",
    "-  C'est la colonne clean_text_embeddings qui sera utilisée pour les embeddings."
   ],
   "id": "e130531f31fb4315"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Charger le fichier CSV nettoyé",
   "id": "3d87f719c46eedd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:17:14.964845Z",
     "start_time": "2024-10-18T08:17:14.959221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verification version de tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "id": "e1c42060620514e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:17:24.419451Z",
     "start_time": "2024-10-18T08:17:15.073189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin relatif pour charger les données nettoyées\n",
    "file_path = os.path.join(\"..\", \"data\", \"cleaned_data_with_text_for_models.csv\")\n",
    "\n",
    "# Chargement du DataFrame nettoyé\n",
    "data = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# Vérification du contenu du DataFrame"
   ],
   "id": "32e4a3afe9437cba",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:17:24.596129Z",
     "start_time": "2024-10-18T08:17:24.443439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Réinitialiser l'index pour récupérer toutes les colonnes, y compris 'text' si elle est utilisée comme index\n",
    "data = data.reset_index()\n",
    "\n",
    "# Vérifier les colonnes disponibles après réinitialisation de l'index\n",
    "print(data.columns)\n"
   ],
   "id": "96b0d02836e331ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'clean_text_tfidf', 'clean_text_embeddings', 'clean_text_bert',\n",
      "       'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:17:24.898303Z",
     "start_time": "2024-10-18T08:17:24.618792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataframe info\n",
    "data.info()"
   ],
   "id": "93044ff2a6fbce5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count    Dtype \n",
      "---  ------                 --------------    ----- \n",
      " 0   text                   1600000 non-null  object\n",
      " 1   clean_text_tfidf       1592857 non-null  object\n",
      " 2   clean_text_embeddings  1596608 non-null  object\n",
      " 3   clean_text_bert        1600000 non-null  object\n",
      " 4   target                 1600000 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:17:25.200994Z",
     "start_time": "2024-10-18T08:17:24.925439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Valeurs manquantes\n",
    "print(data.isnull().sum())"
   ],
   "id": "57ece347a263b0a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                        0\n",
      "clean_text_tfidf         7143\n",
      "clean_text_embeddings    3392\n",
      "clean_text_bert             0\n",
      "target                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:17:25.295199Z",
     "start_time": "2024-10-18T08:17:25.226754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filtrer les lignes avec des valeurs manquantes dans la colonne 'clean_text_embeddings'\n",
    "missing_embeddings = data[data['clean_text_embeddings'].isnull()]\n",
    "\n",
    "# Afficher deux exemples pour analyser les raisons des valeurs manquantes\n",
    "print(missing_embeddings[['text', 'clean_text_tfidf', 'clean_text_embeddings']].head(2))"
   ],
   "id": "9cc762165073be07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             text clean_text_tfidf clean_text_embeddings\n",
      "208    @mandayyy               NaN                   NaN\n",
      "249  @mandayyy                 NaN                   NaN\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:17:25.581065Z",
     "start_time": "2024-10-18T08:17:25.322650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Supprimer les lignes avec des valeurs manquantes dans la colonne 'clean_text_embeddings'\n",
    "data = data.dropna(subset=['clean_text_embeddings'])\n"
   ],
   "id": "d2889fed2b6fe5dd",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:17:25.877023Z",
     "start_time": "2024-10-18T08:17:25.603389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vérifier les valeurs manquantes après suppression\n",
    "print(data.isnull().sum())"
   ],
   "id": "c5c4e5dafe121336",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                        0\n",
      "clean_text_tfidf         3751\n",
      "clean_text_embeddings       0\n",
      "clean_text_bert             0\n",
      "target                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Étape 1 : Charger les embeddings GloVe et FastText\n",
    "- Les liens pour télécharger les embeddings GloVe et FastText sont les suivants :\n",
    "- https://nlp.stanford.edu/projects/glove/\n",
    "- https://fasttext.cc/docs/en/english-vectors.html\n"
   ],
   "id": "3361dd5221253fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:19:57.857383Z",
     "start_time": "2024-10-18T08:17:25.910201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "\n",
    "# Chemin relatif pour charger les fichiers d'embeddings\n",
    "glove_path = os.path.join(\"..\", \"data\", \"glove.twitter.27B.100d.txt\")\n",
    "fasttext_path = os.path.join(\"..\", \"data\", \"crawl-300d-2M-subword.bin\")\n",
    "\n",
    "# Charger les embeddings GloVe\n",
    "glove_model = KeyedVectors.load_word2vec_format(glove_path, binary=False, no_header=True)\n",
    "\n",
    "# Charger les embeddings FastText (format Facebook binaire)\n",
    "fasttext_model = load_facebook_vectors(fasttext_path)\n"
   ],
   "id": "c2d83fbbca438645",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Étape 2 : Créer une fonction pour générer une matrice d'embeddings\n",
    "- Créer une matrice d'embeddings pour chaque modèle, basée sur le vocabulaire des données textuelles."
   ],
   "id": "dc8f14eccfeb1737"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:19:57.896811Z",
     "start_time": "2024-10-18T08:19:57.889324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fonction pour créer la matrice d'embeddings\n",
    "def create_embedding_matrix(embedding_model, vocab, embedding_dim):\n",
    "    embedding_matrix = np.zeros((len(vocab) + 1, embedding_dim))\n",
    "    for word, i in vocab.items():\n",
    "        if word in embedding_model:\n",
    "            embedding_matrix[i] = embedding_model[word]\n",
    "        else:\n",
    "            # Si le mot n'est pas trouvé dans les embeddings, laisser un vecteur de zéros\n",
    "            embedding_matrix[i] = np.zeros(embedding_dim)\n",
    "    return embedding_matrix\n"
   ],
   "id": "6e1bcc9f182aba0b",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Étape 3 : Préparer le tokenizer et les données\n",
    "- Avant de créer le réseau de neurones, nous devons tokeniser le texte et préparer les données."
   ],
   "id": "51b84190262530be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:20:13.670751Z",
     "start_time": "2024-10-18T08:19:57.929711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Tokenisation des textes nettoyés pour les word embeddings\n",
    "num_words = 10000\n",
    "max_sequence_length = 100\n",
    "\n",
    "# Utiliser TextVectorization pour transformer les textes\n",
    "tv_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=num_words,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_sequence_length\n",
    ")\n",
    "\n",
    "# Adapter TextVectorization sur les textes\n",
    "tv_layer.adapt(data['clean_text_embeddings'])\n",
    "\n",
    "# Convertir les textes en séquences\n",
    "X = tv_layer(data['clean_text_embeddings'])\n",
    "\n",
    "# Convertir le Tensor en tableau NumPy\n",
    "X = X.numpy()\n",
    "\n",
    "# Préparer les labels\n",
    "y = data['target'].values  # Assurez-vous que y est également un tableau NumPy\n",
    "\n",
    "# Division des données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "486307e6877516e0",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Cellule countvectorizer pour les embeddings GloVe et FastText (transformer les textes en vecteurs)\n",
    "- Nous utiliserons les textes déjà nettoyés pour les word embeddings à partir de la colonne clean_text_embeddings."
   ],
   "id": "e56cb41d2ce94229"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:20:14.021849Z",
     "start_time": "2024-10-18T08:20:13.695059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "# Sous-échantillonnage des données à 1 % pour tester rapidement le pipeline\n",
    "data_sample = data.sample(frac=0.001, random_state=42)\n",
    "\n",
    "# Utiliser CountVectorizer pour transformer les textes\n",
    "num_words = 10000\n",
    "vectorizer = CountVectorizer(max_features=num_words)\n",
    "\n",
    "# Adapter et transformer les textes\n",
    "X = vectorizer.fit_transform(data_sample['clean_text_embeddings'])\n",
    "\n",
    "# Padding manuel des séquences pour une longueur maximale de 100\n",
    "X_padded = hstack([X, np.zeros((X.shape[0], max(0, 100 - X.shape[1])))]).A\n",
    "\n",
    "# Préparer les labels\n",
    "y = data_sample['target'].values\n",
    "\n",
    "# Division des données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "8f7c6fb6cad37823",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Créer et entraîner les modèles avec GloVe et FastText\n",
    "- Nous allons maintenant construire et entraîner les modèles avec les embeddings GloVe et FastText."
   ],
   "id": "2d17ebed06bbc8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- a) Modèle de réseau de neurones :",
   "id": "4b61145740c0e51a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:20:14.050215Z",
     "start_time": "2024-10-18T08:20:14.041222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Utilisation de tf.keras pour construire le modèle\n",
    "def build_model(embedding_matrix, input_length):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                                        output_dim=embedding_matrix.shape[1],\n",
    "                                        weights=[embedding_matrix],\n",
    "                                        input_length=input_length,\n",
    "                                        trainable=False))  # Ne pas entraîner les embeddings\n",
    "    model.add(tf.keras.layers.LSTM(128, return_sequences=False))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Classification binaire\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ],
   "id": "19e582192f197d04",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- b) Entraînement du modèle avec GloVe :",
   "id": "712343f52d045a52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:20:14.128947Z",
     "start_time": "2024-10-18T08:20:14.083968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Créer la matrice d'embeddings pour GloVe\n",
    "def create_embedding_matrix(glove_model, word_index, embedding_dim):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if word in glove_model:\n",
    "            embedding_vector = glove_model[word]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "# Créer un tokenizer et l'ajuster sur les textes originaux\n",
    "# Remplacez 'data_sample' par le DataFrame qui contient vos données textuelles\n",
    "num_words = 10000  # Assurez-vous que ce nombre correspond à vos besoins\n",
    "texts = data_sample['clean_text_embeddings']\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(texts)"
   ],
   "id": "12e2425d8b9e8fcf",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:28:45.177159Z",
     "start_time": "2024-10-18T08:20:14.153832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Créer la matrice d'embeddings pour GloVe\n",
    "embedding_dim_glove = 100  # Taille des vecteurs d'embeddings pour GloVe\n",
    "embedding_matrix_glove = create_embedding_matrix(glove_model, tokenizer.word_index, embedding_dim_glove)\n",
    "\n",
    "# Construire et entraîner le modèle avec GloVe\n",
    "model_glove = build_model(embedding_matrix_glove, input_length=100)\n",
    "history_glove = model_glove.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n"
   ],
   "id": "a8017b3b69012c59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m100s\u001B[0m 2s/step - accuracy: 0.4949 - loss: 0.6919 - val_accuracy: 0.5188 - val_loss: 0.6982\n",
      "Epoch 2/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m101s\u001B[0m 3s/step - accuracy: 0.5720 - loss: 0.6811 - val_accuracy: 0.5344 - val_loss: 0.6916\n",
      "Epoch 3/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m102s\u001B[0m 3s/step - accuracy: 0.5609 - loss: 0.6830 - val_accuracy: 0.5312 - val_loss: 0.6897\n",
      "Epoch 4/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m104s\u001B[0m 3s/step - accuracy: 0.5303 - loss: 0.6849 - val_accuracy: 0.5281 - val_loss: 0.6899\n",
      "Epoch 5/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m104s\u001B[0m 3s/step - accuracy: 0.5722 - loss: 0.6816 - val_accuracy: 0.5125 - val_loss: 0.6888\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- c) Entraînement du modèle avec FastText :",
   "id": "fcaf924a4ee54405"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:39:05.959430Z",
     "start_time": "2024-10-18T08:28:45.207128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Créer la matrice d'embeddings pour FastText\n",
    "embedding_dim_fasttext = 300  # Taille des vecteurs d'embeddings pour FastText\n",
    "embedding_matrix_fasttext = create_embedding_matrix(fasttext_model, tokenizer.word_index, embedding_dim_fasttext)\n",
    "\n",
    "# Construire et entraîner le modèle avec FastText\n",
    "input_length = 100  # La longueur des séquences padding\n",
    "model_fasttext = build_model(embedding_matrix_fasttext, input_length=input_length)\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_fasttext = model_fasttext.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n"
   ],
   "id": "30e4eec24174213b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m127s\u001B[0m 3s/step - accuracy: 0.4846 - loss: 0.6947 - val_accuracy: 0.5094 - val_loss: 0.6931\n",
      "Epoch 2/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m123s\u001B[0m 3s/step - accuracy: 0.5419 - loss: 0.6897 - val_accuracy: 0.5031 - val_loss: 0.6899\n",
      "Epoch 3/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m125s\u001B[0m 3s/step - accuracy: 0.5309 - loss: 0.6845 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
      "Epoch 4/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m122s\u001B[0m 3s/step - accuracy: 0.5385 - loss: 0.6824 - val_accuracy: 0.5031 - val_loss: 0.6921\n",
      "Epoch 5/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m124s\u001B[0m 3s/step - accuracy: 0.5535 - loss: 0.6863 - val_accuracy: 0.5281 - val_loss: 0.6941\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. Enregistrer les expérimentations avec MLFlow",
   "id": "5959befa2aba5fea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- a) Enregistrer les résultats pour GloVe :",
   "id": "fd4cb7ffd0e9f50a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:54:36.624946Z",
     "start_time": "2024-10-18T08:54:36.526609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "# Enregistrer les résultats pour GloVe\n",
    "mlflow.start_run(run_name=\"GloVe Embedding\")\n",
    "mlflow.log_param(\"embedding\", \"GloVe\")\n",
    "mlflow.log_param(\"embedding_dim\", embedding_dim_glove)\n",
    "mlflow.log_metric(\"accuracy\", model_glove.evaluate(X_test, y_test)[1])\n",
    "mlflow.keras.log_model(model_glove, \"model_glove\")\n",
    "mlflow.end_run()"
   ],
   "id": "e1ba51676026e25f",
   "outputs": [
    {
     "ename": "UnsupportedModelRegistryStoreURIException",
     "evalue": " Model registry functionality is unavailable; got unsupported URI 'D:\\OC_IA\\P7\\OC_IA_P7_analyse_sentiments_deep_Learning\\mlruns' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\P7te\\Lib\\site-packages\\mlflow\\tracking\\registry.py:82\u001B[0m, in \u001B[0;36mStoreRegistry.get_store_builder\u001B[1;34m(self, store_uri)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 82\u001B[0m     store_builder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_registry\u001B[49m\u001B[43m[\u001B[49m\u001B[43mscheme\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[1;31mKeyError\u001B[0m: 'd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mUnsupportedModelRegistryStoreURIException\u001B[0m Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[70], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmlflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Enregistrer les résultats pour GloVe\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGloVe Embedding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mlog_param(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGloVe\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      7\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mlog_param(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding_dim\u001B[39m\u001B[38;5;124m\"\u001B[39m, embedding_dim_glove)\n",
      "File \u001B[1;32m~\\.conda\\envs\\P7te\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:328\u001B[0m, in \u001B[0;36mstart_run\u001B[1;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001B[0m\n\u001B[0;32m    320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(_active_run_stack) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nested:\n\u001B[0;32m    321\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[0;32m    322\u001B[0m         (\n\u001B[0;32m    323\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun with UUID \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is already active. To start a new run, first end the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    326\u001B[0m         )\u001B[38;5;241m.\u001B[39mformat(_active_run_stack[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id)\n\u001B[0;32m    327\u001B[0m     )\n\u001B[1;32m--> 328\u001B[0m client \u001B[38;5;241m=\u001B[39m \u001B[43mMlflowClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_id:\n\u001B[0;32m    330\u001B[0m     existing_run_id \u001B[38;5;241m=\u001B[39m run_id\n",
      "File \u001B[1;32m~\\.conda\\envs\\P7te\\Lib\\site-packages\\mlflow\\tracking\\client.py:134\u001B[0m, in \u001B[0;36mMlflowClient.__init__\u001B[1;34m(self, tracking_uri, registry_uri)\u001B[0m\n\u001B[0;32m    132\u001B[0m final_tracking_uri \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39m_resolve_tracking_uri(tracking_uri)\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registry_uri \u001B[38;5;241m=\u001B[39m registry_utils\u001B[38;5;241m.\u001B[39m_resolve_registry_uri(registry_uri, tracking_uri)\n\u001B[1;32m--> 134\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tracking_client \u001B[38;5;241m=\u001B[39m \u001B[43mTrackingServiceClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfinal_tracking_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\P7te\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:82\u001B[0m, in \u001B[0;36mTrackingServiceClient.__init__\u001B[1;34m(self, tracking_uri)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtracking_uri \u001B[38;5;241m=\u001B[39m tracking_uri\n\u001B[0;32m     78\u001B[0m \u001B[38;5;66;03m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001B[39;00m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;66;03m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# property method to ensure that the client is serializable, even if the store is not\u001B[39;00m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# self.store\u001B[39;00m\n\u001B[1;32m---> 82\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstore\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\P7te\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:86\u001B[0m, in \u001B[0;36mTrackingServiceClient.store\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstore\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_store\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtracking_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\P7te\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:208\u001B[0m, in \u001B[0;36m_get_store\u001B[1;34m(store_uri, artifact_uri)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_store\u001B[39m(store_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, artifact_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 208\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_tracking_store_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_store\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstore_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\P7te\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:42\u001B[0m, in \u001B[0;36mTrackingStoreRegistry.get_store\u001B[1;34m(self, store_uri, artifact_uri)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmlflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtracking\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tracking_service\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[0;32m     41\u001B[0m resolved_store_uri \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39m_resolve_tracking_uri(store_uri)\n\u001B[1;32m---> 42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_store_with_resolved_uri\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresolved_store_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\P7te\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:51\u001B[0m, in \u001B[0;36mTrackingStoreRegistry._get_store_with_resolved_uri\u001B[1;34m(self, resolved_store_uri, artifact_uri)\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;129m@lru_cache\u001B[39m(maxsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_store_with_resolved_uri\u001B[39m(\u001B[38;5;28mself\u001B[39m, resolved_store_uri, artifact_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     46\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;124;03m    Retrieve the store associated with a resolved (non-None) store URI and an artifact URI.\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;124;03m    Caching is done on resolved URIs because the meaning of an unresolved (None) URI may change\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;124;03m    depending on external configuration, such as environment variables\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 51\u001B[0m     builder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_store_builder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresolved_store_uri\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m builder(store_uri\u001B[38;5;241m=\u001B[39mresolved_store_uri, artifact_uri\u001B[38;5;241m=\u001B[39martifact_uri)\n",
      "File \u001B[1;32m~\\.conda\\envs\\P7te\\Lib\\site-packages\\mlflow\\tracking\\registry.py:84\u001B[0m, in \u001B[0;36mStoreRegistry.get_store_builder\u001B[1;34m(self, store_uri)\u001B[0m\n\u001B[0;32m     82\u001B[0m     store_builder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registry[scheme]\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m---> 84\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m UnsupportedModelRegistryStoreURIException(\n\u001B[0;32m     85\u001B[0m         unsupported_uri\u001B[38;5;241m=\u001B[39mstore_uri, supported_uri_schemes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registry\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[0;32m     86\u001B[0m     )\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m store_builder\n",
      "\u001B[1;31mUnsupportedModelRegistryStoreURIException\u001B[0m:  Model registry functionality is unavailable; got unsupported URI 'D:\\OC_IA\\P7\\OC_IA_P7_analyse_sentiments_deep_Learning\\mlruns' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations."
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- b) Enregistrer les résultats pour FastText :",
   "id": "8cb066147e80c96b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Enregistrer les résultats pour FastText\n",
    "mlflow.start_run(run_name=\"FastText Embedding\")\n",
    "mlflow.log_param(\"embedding\", \"FastText\")\n",
    "mlflow.log_param(\"embedding_dim\", embedding_dim_fasttext)\n",
    "mlflow.log_metric(\"accuracy\", model_fasttext.evaluate(X_test, y_test)[1])\n",
    "mlflow.keras.log_model(model_fasttext, \"model_fasttext\")\n",
    "mlflow.end_run()"
   ],
   "id": "7f2318068a21fc4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7. Conclusion\n",
    "- Ce code utilise le fichier cleaned_data_with_text_for_models.csv et applique les word embeddings GloVe et FastText. Nous avons modifié le code pour utiliser les textes déjà nettoyés dans la colonne clean_text_embeddings. Après avoir entraîné les modèles, nous enregistrons les résultats et les modèles dans MLFlow afin de comparer les performances des deux embeddings et de sélectionner le meilleur."
   ],
   "id": "b16bb58980ad2dee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
