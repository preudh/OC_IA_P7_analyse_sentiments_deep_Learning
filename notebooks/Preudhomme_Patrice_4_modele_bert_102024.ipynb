{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Développement du \"Modèle avancé BERT\"\n",
    "Ce notebook implémente un modèle de classification de sentiments utilisant BERT. \n",
    "Nous allons fine-tuner un modèle pré-entraîné sur notre jeu de données, puis évaluer ses performances et enregistrer les résultats avec MLFlow.\n"
   ],
   "id": "69c28ee259661807"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "aaf41c1bd16f8f55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:43:13.743904Z",
     "start_time": "2024-10-20T08:43:10.265249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "data_path = \"../data/training.1600000.processed.noemoticon.csv\"\n",
    "data = pd.read_csv(data_path, encoding='latin-1', header=None)"
   ],
   "id": "6bf255f077809d8b",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:43:13.844667Z",
     "start_time": "2024-10-20T08:43:13.759339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Afficher un échantillon des données\n",
    "data.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "data_sample = data[['target', 'text']].sample(5)\n",
    "display(data_sample)"
   ],
   "id": "64c729c9c495a7b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         target                                               text\n",
       "538545        0  @Lilayy WHAT !?!?!? There's a picture of Miley...\n",
       "1286566       4    I'm so Taylor Swift and Katy Perry. Love them. \n",
       "1056735       4                @adisti  thanks for today, babe! :*\n",
       "947654        4  Rumor has it that Girls Gone Wild is filming i...\n",
       "1148088       4      @quintosential all of your ontd tags are WIN "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538545</th>\n",
       "      <td>0</td>\n",
       "      <td>@Lilayy WHAT !?!?!? There's a picture of Miley...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286566</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm so Taylor Swift and Katy Perry. Love them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056735</th>\n",
       "      <td>4</td>\n",
       "      <td>@adisti  thanks for today, babe! :*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947654</th>\n",
       "      <td>4</td>\n",
       "      <td>Rumor has it that Girls Gone Wild is filming i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148088</th>\n",
       "      <td>4</td>\n",
       "      <td>@quintosential all of your ontd tags are WIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:43:14.668337Z",
     "start_time": "2024-10-20T08:43:13.870753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformer les valeurs de 'target' : 0 reste 0 (négatif) et 4 devient 1 (positif)\n",
    "data['target'] = data['target'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# Vérifier un échantillon après la transformation\n",
    "data_sample = data[['target', 'text']].sample(5)\n",
    "display(data_sample)\n"
   ],
   "id": "4c61231c0a4aeb7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         target                                               text\n",
       "308563        0  We just got in from our midnight dig walk. So ...\n",
       "708522        0  @GabeAlvarez that's EXACTLY what I said this m...\n",
       "1553750       1                 Gettin Ready Gunna Chill 4 A Lido \n",
       "603440        0  @hayles All the info is missing tho, well on m...\n",
       "521237        0  Hot n sweaty on turnpike lane  http://twitpic...."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308563</th>\n",
       "      <td>0</td>\n",
       "      <td>We just got in from our midnight dig walk. So ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708522</th>\n",
       "      <td>0</td>\n",
       "      <td>@GabeAlvarez that's EXACTLY what I said this m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553750</th>\n",
       "      <td>1</td>\n",
       "      <td>Gettin Ready Gunna Chill 4 A Lido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603440</th>\n",
       "      <td>0</td>\n",
       "      <td>@hayles All the info is missing tho, well on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521237</th>\n",
       "      <td>0</td>\n",
       "      <td>Hot n sweaty on turnpike lane  http://twitpic....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:43:17.513790Z",
     "start_time": "2024-10-20T08:43:14.699146Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install transformers",
   "id": "d8087238b1d659d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:43:18.554326Z",
     "start_time": "2024-10-20T08:43:17.547718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Définir la taille de l'échantillon\n",
    "sample_size = 1000\n",
    "\n",
    "# Limiter le dataset à un échantillon stratifié de 10000 lignes basé sur la colonne 'target'\n",
    "sample_data = data.groupby('target', group_keys=False).apply(lambda x: x.sample(int(sample_size * len(x) / len(data)), random_state=42))\n",
    "\n",
    "# Vérifier la distribution des classes dans l'échantillon par rapport au dataset d'origine\n",
    "print(\"Distribution des classes dans le dataset d'origine :\")\n",
    "print(data['target'].value_counts(normalize=True))\n",
    "print(\"\\nDistribution des classes dans l'échantillon :\")\n",
    "print(sample_data['target'].value_counts(normalize=True))\n",
    "\n",
    "# Prétraitement des données textuelles sur cet échantillon\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = tokenizer(text, max_length=128, truncation=True, padding='max_length', return_tensors='tf')\n",
    "    return tokens\n",
    "\n",
    "# Appliquer la fonction de prétraitement\n",
    "sample_data['tokens'] = sample_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Afficher un échantillon des données après tokenisation\n",
    "sample_data_sample = sample_data[['target', 'tokens']].sample(5)\n",
    "display(sample_data_sample)\n"
   ],
   "id": "6902af0fd3bfca6b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pat\\AppData\\Local\\Temp\\ipykernel_22424\\3146143680.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sample_data = data.groupby('target', group_keys=False).apply(lambda x: x.sample(int(sample_size * len(x) / len(data)), random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans le dataset d'origine :\n",
      "target\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribution des classes dans l'échantillon :\n",
      "target\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         target                                       tokens\n",
       "1082625       1  [input_ids, token_type_ids, attention_mask]\n",
       "1416899       1  [input_ids, token_type_ids, attention_mask]\n",
       "1130118       1  [input_ids, token_type_ids, attention_mask]\n",
       "480285        0  [input_ids, token_type_ids, attention_mask]\n",
       "421299        0  [input_ids, token_type_ids, attention_mask]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1082625</th>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416899</th>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130118</th>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480285</th>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421299</th>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Charger et préparer le modèle BERT :",
   "id": "d4ab7c84ae0ebd0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:43:20.974629Z",
     "start_time": "2024-10-20T08:43:18.608925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chargement et préparation du modèle BERT pré-entraîné\n",
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Charger le modèle BERT pré-entraîné\n",
    "model_bert = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Compilations du modèle\n",
    "model_bert.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n"
   ],
   "id": "31e23981202903d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Préparer les données et entraîner le modèle ",
   "id": "45f1aa940507a6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:57:59.205511Z",
     "start_time": "2024-10-20T08:43:20.981702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract necessary elements for BERT (input_ids and attention_mask)\n",
    "input_ids = np.array([t['input_ids'].numpy()[0] for t in sample_data['tokens']])\n",
    "attention_masks = np.array([t['attention_mask'].numpy()[0] for t in sample_data['tokens']])\n",
    "y = np.array(sample_data['target'].values)\n",
    "\n",
    "# Split the data using train_test_split\n",
    "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
    "    input_ids, attention_masks, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert back to TensorFlow tensors\n",
    "X_train_ids = tf.convert_to_tensor(X_train_ids)\n",
    "X_test_ids = tf.convert_to_tensor(X_test_ids)\n",
    "X_train_mask = tf.convert_to_tensor(X_train_mask)\n",
    "X_test_mask = tf.convert_to_tensor(X_test_mask)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "# Prepare TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\"input_ids\": X_train_ids, \"attention_mask\": X_train_mask}, y_train)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\"input_ids\": X_test_ids, \"attention_mask\": X_test_mask}, y_test)).batch(32)\n",
    "\n",
    "# Train the model\n",
    "history = model_bert.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=3\n",
    ")\n"
   ],
   "id": "fb989b5df943c934",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "25/25 [==============================] - 305s 11s/step - loss: 0.6879 - accuracy: 0.5587 - val_loss: 0.6320 - val_accuracy: 0.6350\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 276s 11s/step - loss: 0.5402 - accuracy: 0.7375 - val_loss: 0.5430 - val_accuracy: 0.7350\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 297s 12s/step - loss: 0.3273 - accuracy: 0.8763 - val_loss: 0.5050 - val_accuracy: 0.7750\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T09:02:06.635254Z",
     "start_time": "2024-10-20T09:01:44.597257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Évaluation des performances\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Préparer les données de test dans le bon format\n",
    "test_inputs = {\"input_ids\": X_test_ids, \"attention_mask\": X_test_mask}\n",
    "\n",
    "# Prédictions\n",
    "y_pred = model_bert.predict(test_inputs)\n",
    "y_pred_labels = tf.argmax(y_pred.logits, axis=1).numpy()\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(classification_report(y_test, y_pred_labels))\n"
   ],
   "id": "7be9547cfe208a80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 22s 3s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77        96\n",
      "           1       0.80      0.75      0.78       104\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.78      0.78      0.77       200\n",
      "weighted avg       0.78      0.78      0.78       200\n",
      "\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "D'après le rapport de classification, voici les observations :\n",
    "\n",
    "### Précision, rappel et F1-score par classe :\n",
    "- **Classe 0 (Négatif)** :\n",
    "  - Précision : 0.75\n",
    "  - Rappel : 0.80\n",
    "  - F1-score : 0.77\n",
    "  - Le modèle détecte correctement 75 % des exemples négatifs qu'il prédit, et identifie 80 % des véritables exemples négatifs.\n",
    "\n",
    "- **Classe 1 (Positif)** :\n",
    "  - Précision : 0.80\n",
    "  - Rappel : 0.75\n",
    "  - F1-score : 0.78\n",
    "  - Le modèle est plus précis dans ses prédictions pour cette classe, mais il manque 25 % des exemples positifs.\n",
    "\n",
    "### Moyennes globales :\n",
    "- **Accuracy (Exactitude)** : 0.78, indiquant que 78 % des prédictions totales sont correctes.\n",
    "- **Macro avg** : Les moyennes arithmétiques des scores (précision, rappel, F1-score) pour les deux classes sont équilibrées, toutes autour de 0.78.\n",
    "- **Weighted avg** : Les moyennes pondérées, tenant compte de la proportion de chaque classe, montrent également une performance cohérente à 0.78.\n",
    "\n",
    "### Interprétation :\n",
    "Le modèle montre une performance correcte, mais avec des marges d'amélioration possibles. Un F1-score de 0.78 reste acceptable, mais un ajustement des hyperparamètres (comme le taux d'apprentissage ou le nombre d'époques) pourrait optimiser les résultats. Vérifier s'il y a un déséquilibre entre les classes serait également pertinent pour appliquer des techniques de rééquilibrage.\n",
    "\n",
    "### Recommandations pour l'amélioration :\n",
    "- Augmenter le nombre d'époques pour voir si les performances s'améliorent sans sur-ajuster le modèle.\n",
    "- Utiliser des techniques de **data augmentation** pour renforcer la généralisation, surtout si la taille du dataset est limitée.\n",
    "- Expérimenter avec des variantes de BERT ou ajuster plus finement certaines couches pour cette tâche spécifique pourrait aussi offrir des améliorations."
   ],
   "id": "6193a142b7fd4119"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T09:04:58.487611Z",
     "start_time": "2024-10-20T09:04:30.108015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enregistrement des expérimentations et des résultats avec MLFlow\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import os\n",
    "\n",
    "# Chemin relatif pour le dossier \"models\"\n",
    "relative_models_path = os.path.join(\"..\", \"models\")\n",
    "\n",
    "# Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "mlflow.set_tracking_uri(relative_models_path)\n",
    "\n",
    "# Créer une nouvelle expérience ou utiliser une existante\n",
    "experiment_name = \"BERT_Embedding_Experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Démarrer une nouvelle session MLFlow pour BERT\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model\", \"BERT\")\n",
    "    mlflow.log_param(\"epochs\", 3)\n",
    "    mlflow.log_metric(\"accuracy\", history.history['accuracy'][-1])\n",
    "    mlflow.log_metric(\"val_accuracy\", history.history['val_accuracy'][-1])\n",
    "    \n",
    "    # Enregistrer le modèle BERT comme artefact\n",
    "    mlflow.keras.log_model(model_bert, \"model_bert\")\n",
    "\n",
    "print(f\"Modèle BERT enregistré dans {relative_models_path}.\")"
   ],
   "id": "cd1f4237e971be43",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 11:04:31 INFO mlflow.tracking.fluent: Experiment with name 'BERT_Embedding_Experiment' does not exist. Creating a new experiment.\n",
      "2024/10/20 11:04:31 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2024/10/20 11:04:31 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\transformers\\generation\\tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n",
      "2024/10/20 11:04:57 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\pat\\AppData\\Local\\Temp\\tmpb_ba2xzu\\model, flavor: keras). Fall back to return ['keras==3.6.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/10/20 11:04:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle BERT enregistré dans ..\\models.\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Conclusion\n",
    "Le modèle BERT a été fine-tuné sur notre jeu de données pour l'analyse de sentiments. \n",
    "Les résultats ont été enregistrés avec MLFlow, et le modèle a montré des performances prometteuses en termes de précision.\n"
   ],
   "id": "e1947eda1d6f20da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d33a1f527dbcd43b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
