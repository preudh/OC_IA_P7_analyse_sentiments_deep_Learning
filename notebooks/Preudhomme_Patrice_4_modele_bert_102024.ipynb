{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Développement du \"Modèle avancé BERT\"\n",
    "Ce notebook implémente un modèle de classification de sentiments utilisant BERT. \n",
    "Nous allons fine-tuner un modèle pré-entraîné sur notre jeu de données, puis évaluer ses performances et enregistrer les résultats avec MLFlow.\n"
   ],
   "id": "69c28ee259661807"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "aaf41c1bd16f8f55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T05:51:10.179311Z",
     "start_time": "2024-10-22T05:51:05.170293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "data_path = \"../data/training.1600000.processed.noemoticon.csv\"\n",
    "data = pd.read_csv(data_path, encoding='latin-1', header=None)"
   ],
   "id": "6bf255f077809d8b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T05:51:10.345409Z",
     "start_time": "2024-10-22T05:51:10.191321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Afficher un échantillon des données\n",
    "data.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "data_sample = data[['target', 'text']].sample(5)\n",
    "display(data_sample)"
   ],
   "id": "64c729c9c495a7b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         target                                               text\n",
       "171132        0                   i need to get my computer fixed \n",
       "266039        0  is f-ing exhausted. Don't think I'm gonna make...\n",
       "906655        4  @dannisaywhat LOL kk i've sent u a friend requ...\n",
       "1188597       4  @Dannymcfly hey we brazilians have amazing ass...\n",
       "799186        0                        @AgentBooth what happened? "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171132</th>\n",
       "      <td>0</td>\n",
       "      <td>i need to get my computer fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266039</th>\n",
       "      <td>0</td>\n",
       "      <td>is f-ing exhausted. Don't think I'm gonna make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906655</th>\n",
       "      <td>4</td>\n",
       "      <td>@dannisaywhat LOL kk i've sent u a friend requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188597</th>\n",
       "      <td>4</td>\n",
       "      <td>@Dannymcfly hey we brazilians have amazing ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799186</th>\n",
       "      <td>0</td>\n",
       "      <td>@AgentBooth what happened?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T05:51:11.693310Z",
     "start_time": "2024-10-22T05:51:10.883045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformer les valeurs de 'target' : 0 reste 0 (négatif) et 4 devient 1 (positif)\n",
    "data['target'] = data['target'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# Vérifier un échantillon après la transformation\n",
    "data_sample = data[['target', 'text']].sample(5)\n",
    "display(data_sample)\n"
   ],
   "id": "4c61231c0a4aeb7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         target                                               text\n",
       "345755        0  @stefii_wefii ...a sleeping problem because I ...\n",
       "606702        0  I can haz phone! Crap! Now I'm &quot;reachable...\n",
       "881348        1  @TheGeniousphere I think,you are already know ...\n",
       "1443971       1  @drewryanscott move hereee lol i think you'll ...\n",
       "1322176       1                  @SkoutTradeFair oh no! Poor you! "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345755</th>\n",
       "      <td>0</td>\n",
       "      <td>@stefii_wefii ...a sleeping problem because I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606702</th>\n",
       "      <td>0</td>\n",
       "      <td>I can haz phone! Crap! Now I'm &amp;quot;reachable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881348</th>\n",
       "      <td>1</td>\n",
       "      <td>@TheGeniousphere I think,you are already know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443971</th>\n",
       "      <td>1</td>\n",
       "      <td>@drewryanscott move hereee lol i think you'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322176</th>\n",
       "      <td>1</td>\n",
       "      <td>@SkoutTradeFair oh no! Poor you!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T05:51:16.691409Z",
     "start_time": "2024-10-22T05:51:11.713319Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install transformers",
   "id": "d8087238b1d659d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pat\\.conda\\envs\\p7te\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T05:51:26.334351Z",
     "start_time": "2024-10-22T05:51:16.727753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Définir la taille de l'échantillon\n",
    "sample_size = 1000\n",
    "\n",
    "# Limiter le dataset à un échantillon stratifié de 10000 lignes basé sur la colonne 'target'\n",
    "sample_data = data.groupby('target', group_keys=False).apply(lambda x: x.sample(int(sample_size * len(x) / len(data)), random_state=42))\n",
    "\n",
    "# Vérifier la distribution des classes dans l'échantillon par rapport au dataset d'origine\n",
    "print(\"Distribution des classes dans le dataset d'origine :\")\n",
    "print(data['target'].value_counts(normalize=True))\n",
    "print(\"\\nDistribution des classes dans l'échantillon :\")\n",
    "print(sample_data['target'].value_counts(normalize=True))\n",
    "\n",
    "# Prétraitement des données textuelles sur cet échantillon\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = tokenizer(text, max_length=128, truncation=True, padding='max_length', return_tensors='tf')\n",
    "    return tokens\n",
    "\n",
    "# Appliquer la fonction de prétraitement\n",
    "sample_data['tokens'] = sample_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Afficher un échantillon des données après tokenisation\n",
    "sample_data_sample = sample_data[['target', 'tokens']].sample(5)\n",
    "display(sample_data_sample)\n"
   ],
   "id": "6902af0fd3bfca6b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\pat\\AppData\\Local\\Temp\\ipykernel_19076\\3146143680.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sample_data = data.groupby('target', group_keys=False).apply(lambda x: x.sample(int(sample_size * len(x) / len(data)), random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans le dataset d'origine :\n",
      "target\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribution des classes dans l'échantillon :\n",
      "target\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         target                                       tokens\n",
       "384253        0  [input_ids, token_type_ids, attention_mask]\n",
       "664875        0  [input_ids, token_type_ids, attention_mask]\n",
       "735817        0  [input_ids, token_type_ids, attention_mask]\n",
       "844006        1  [input_ids, token_type_ids, attention_mask]\n",
       "1498998       1  [input_ids, token_type_ids, attention_mask]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384253</th>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664875</th>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735817</th>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844006</th>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498998</th>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Charger et préparer le modèle BERT :",
   "id": "d4ab7c84ae0ebd0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T05:51:37.236182Z",
     "start_time": "2024-10-22T05:51:26.369515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chargement et préparation du modèle BERT pré-entraîné\n",
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Charger le modèle BERT pré-entraîné\n",
    "model_bert = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Compilations du modèle\n",
    "model_bert.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n"
   ],
   "id": "31e23981202903d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Préparer les données et entraîner le modèle ",
   "id": "45f1aa940507a6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T06:04:32.213838Z",
     "start_time": "2024-10-22T05:51:37.246192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract necessary elements for BERT (input_ids and attention_mask)\n",
    "input_ids = np.array([t['input_ids'].numpy()[0] for t in sample_data['tokens']])\n",
    "attention_masks = np.array([t['attention_mask'].numpy()[0] for t in sample_data['tokens']])\n",
    "y = np.array(sample_data['target'].values)\n",
    "\n",
    "# Split the data using train_test_split\n",
    "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
    "    input_ids, attention_masks, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert back to TensorFlow tensors\n",
    "X_train_ids = tf.convert_to_tensor(X_train_ids)\n",
    "X_test_ids = tf.convert_to_tensor(X_test_ids)\n",
    "X_train_mask = tf.convert_to_tensor(X_train_mask)\n",
    "X_test_mask = tf.convert_to_tensor(X_test_mask)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "# Prepare TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\"input_ids\": X_train_ids, \"attention_mask\": X_train_mask}, y_train)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\"input_ids\": X_test_ids, \"attention_mask\": X_test_mask}, y_test)).batch(32)\n",
    "\n",
    "# Train the model\n",
    "history = model_bert.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=3\n",
    ")\n"
   ],
   "id": "fb989b5df943c934",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "25/25 [==============================] - 305s 11s/step - loss: 0.6721 - accuracy: 0.5938 - val_loss: 0.5962 - val_accuracy: 0.6850\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 233s 9s/step - loss: 0.4995 - accuracy: 0.8050 - val_loss: 0.5083 - val_accuracy: 0.7650\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 236s 9s/step - loss: 0.3321 - accuracy: 0.8687 - val_loss: 0.4914 - val_accuracy: 0.7950\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T06:04:52.715329Z",
     "start_time": "2024-10-22T06:04:32.242479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Évaluation des performances\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Préparer les données de test dans le bon format\n",
    "test_inputs = {\"input_ids\": X_test_ids, \"attention_mask\": X_test_mask}\n",
    "\n",
    "# Prédictions\n",
    "y_pred = model_bert.predict(test_inputs)\n",
    "y_pred_labels = tf.argmax(y_pred.logits, axis=1).numpy()\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(classification_report(y_test, y_pred_labels))\n"
   ],
   "id": "7be9547cfe208a80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 20s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78        96\n",
      "           1       0.78      0.85      0.81       104\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.80      0.79      0.79       200\n",
      "weighted avg       0.80      0.80      0.79       200\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### D'après le rapport de classification, voici les observations :\n",
    "\n",
    "### Précision, rappel et F1-score par classe :\n",
    "- **Classe 0** :\n",
    "  - Précision : **0.82**\n",
    "  - Rappel : **0.74**\n",
    "  - F1-score : **0.78**\n",
    "  - **Analyse** : Le modèle détecte correctement 82 % des exemples négatifs qu'il prédit, mais identifie seulement 74 % des véritables exemples négatifs.\n",
    "\n",
    "- **Classe 1** :\n",
    "  - Précision : **0.78**\n",
    "  - Rappel : **0.85**\n",
    "  - F1-score : **0.81**\n",
    "  - **Analyse** : Le modèle est légèrement moins précis pour cette classe (78 % des exemples positifs prédits sont corrects), mais il détecte 85 % des véritables exemples positifs.\n",
    "\n",
    "### Moyennes globales :\n",
    "- **Accuracy (Exactitude)** : **0.80**, indiquant que 80 % des prédictions totales sont correctes.\n",
    "- **Macro avg** : Moyennes arithmétiques des scores (précision, rappel, F1-score) pour les deux classes, autour de **0.79**.\n",
    "- **Weighted avg** : Moyennes pondérées, tenant compte de la proportion de chaque classe, également autour de **0.79**.\n",
    "\n",
    "### Interprétation :\n",
    "Le modèle montre une performance globale correcte, avec un **F1-score moyen de 0.79**. La classe 1 (positif) est mieux détectée que la classe 0 (négatif), mais des marges d'amélioration subsistent, notamment sur le rappel de la classe 0.\n",
    "\n",
    "### Recommandations pour l'amélioration :\n",
    "- **Optimisation des hyperparamètres** : Ajuster le taux d'apprentissage, augmenter les époques ou expérimenter avec des optimisateurs différents.\n",
    "- **Data augmentation** : Augmenter la diversité du dataset pour améliorer la généralisation du modèle.\n",
    "- **Exploration de modèles alternatifs** : Tester des variantes de BERT ou fine-tuner davantage pour cette tâche spécifique.\n",
    "\n",
    "### Conclusion :\n",
    "Les résultats sont solides avec une **accuracy de 80 %** et des scores équilibrés entre les deux classes. Cependant, travailler sur le rappel de la classe 0 et tester des ajustements pourrait encore améliorer les performances.\n",
    "```"
   ],
   "id": "9c1d02b691ad7ce4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T06:05:18.151802Z",
     "start_time": "2024-10-22T06:04:52.746210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "# Chemin absolu pour le dossier \"mlruns\" en utilisant pathlib\n",
    "mlruns_path = Path(\"../mlruns\").resolve()\n",
    "\n",
    "# Vérifier que le dossier \"mlruns\" existe, sinon le créer\n",
    "if not mlruns_path.exists():\n",
    "    mlruns_path.mkdir(parents=True)\n",
    "\n",
    "# Vérifier que le sous-dossier \".trash\" existe, sinon le créer\n",
    "trash_folder = mlruns_path / \".trash\"\n",
    "if not trash_folder.exists():\n",
    "    trash_folder.mkdir(parents=True)\n",
    "\n",
    "# Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "mlflow.set_tracking_uri(mlruns_path.as_uri())\n",
    "\n",
    "# Créer une nouvelle expérience ou utiliser une existante\n",
    "experiment_name = \"BERT_Embedding_Experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Démarrer une nouvelle session MLFlow pour BERT\n",
    "with mlflow.start_run(nested=True):  # Utilisation d'une run imbriquée pour préserver les autres runs\n",
    "    mlflow.log_param(\"model\", \"BERT\")\n",
    "    mlflow.log_param(\"epochs\", 3)\n",
    "    mlflow.log_metric(\"accuracy\", history.history['accuracy'][-1])\n",
    "    mlflow.log_metric(\"val_accuracy\", history.history['val_accuracy'][-1])\n",
    "    \n",
    "    # Enregistrer le modèle BERT comme artefact\n",
    "    mlflow.keras.log_model(model_bert, \"model_bert\")\n",
    "\n",
    "print(f\"Modèle BERT enregistré dans {mlruns_path}.\")\n"
   ],
   "id": "fbc4aee628cd655e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/22 08:04:53 INFO mlflow.tracking.fluent: Experiment with name 'BERT_Embedding_Experiment' does not exist. Creating a new experiment.\n",
      "2024/10/22 08:04:53 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2024/10/22 08:04:53 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\transformers\\generation\\tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n",
      "2024/10/22 08:05:17 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\pat\\AppData\\Local\\Temp\\tmpf5ubqi2f\\model, flavor: keras). Fall back to return ['keras==3.6.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/10/22 08:05:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle BERT enregistré dans D:\\OC_IA\\P7\\OC_IA_P7_analyse_sentiments_deep_Learning\\mlruns.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Conclusion\n",
    "Le modèle BERT a été fine-tuné sur notre jeu de données pour l'analyse de sentiments. \n",
    "Les résultats ont été enregistrés avec MLFlow, et le modèle a montré des performances prometteuses en termes de précision.\n"
   ],
   "id": "e1947eda1d6f20da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d33a1f527dbcd43b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
