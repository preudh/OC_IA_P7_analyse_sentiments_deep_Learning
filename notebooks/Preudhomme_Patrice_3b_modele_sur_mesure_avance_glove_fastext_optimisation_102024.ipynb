{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Charger les embeddings GloVe et FastText\n",
    "- Les liens pour télécharger les embeddings GloVe et FastText sont les suivants :\n",
    "- https://nlp.stanford.edu/projects/glove/\n",
    "- https://fasttext.cc/docs/en/english-vectors.html\n"
   ],
   "id": "3361dd5221253fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Développement du \"Modèle sur mesure avancé\" avec des essais sur au moins deux word embeddings différents et en gardant celui qui permet d’obtenir les meilleures performances. Nous utiliserons Glove et FastText.\n",
    "-  Nous allons construire et entraîner un réseau de neurones pour chaque embedding, évaluer les performances et enregistrer les expérimentations avec MLFlow. \n",
    "-  C'est la colonne clean_text_embeddings qui sera utilisée pour les embeddings.\n",
    "- Par rapport au notebook précédent, nous allons enregistrer des métriques supplémentaires, visualisation des courbes ROC/AUC, et optimisation des hyperparamètres, à intégrer dans le notebook, en gardant le sous-échantillonnage initial pour réduire la charge de calcul."
   ],
   "id": "e130531f31fb4315"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Charger le fichier CSV nettoyé",
   "id": "3d87f719c46eedd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 1 : Vérification de la version de TensorFlow",
   "id": "3362ed5f0dc20a64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:44.433675Z",
     "start_time": "2024-10-20T10:05:44.394861Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "execution_count": 21,
   "source": [
    "# Verification version de tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "id": "e1c42060620514e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 2 : Chargement des données nettoyées",
   "id": "875baae1dc082343"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:58.043528Z",
     "start_time": "2024-10-20T10:05:44.534316Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 22,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin relatif pour charger les données nettoyées\n",
    "file_path = os.path.join(\"..\", \"data\", \"cleaned_data_with_text_for_models.csv\")\n",
    "\n",
    "# Chargement du DataFrame nettoyé\n",
    "data = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# Vérification du contenu du DataFrame"
   ],
   "id": "32e4a3afe9437cba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 3 : Préparation des données",
   "id": "e99706e57c54090b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:58.312977Z",
     "start_time": "2024-10-20T10:05:58.125030Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'clean_text_tfidf', 'clean_text_embeddings', 'clean_text_bert',\n",
      "       'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 23,
   "source": [
    "# Réinitialiser l'index pour récupérer toutes les colonnes, y compris 'text' si elle est utilisée comme index\n",
    "data = data.reset_index()\n",
    "\n",
    "# Vérifier les colonnes disponibles après réinitialisation de l'index\n",
    "print(data.columns)\n",
    "\n",
    "# Dataframe info\n",
    "data.info()\n"
   ],
   "id": "96b0d02836e331ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 4 : Traitement des valeurs manquantes",
   "id": "b325e3d086538619"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Vérifier les valeurs manquantes\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Filtrer les lignes avec des valeurs manquantes dans la colonne 'clean_text_embeddings'\n",
    "missing_embeddings = data[data['clean_text_embeddings'].isnull()]\n",
    "print(missing_embeddings[['text', 'clean_text_tfidf', 'clean_text_embeddings']].head(2))\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes dans la colonne 'clean_text_embeddings'\n",
    "data = data.dropna(subset=['clean_text_embeddings'])\n",
    "\n",
    "# Vérifier les valeurs manquantes après suppression\n",
    "print(data.isnull().sum())\n"
   ],
   "id": "a272258133679551"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 5 : Chargement des embeddings GloVe et FastText",
   "id": "dcfec0a326cf5aff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "\n",
    "# Chemin relatif pour charger les fichiers d'embeddings\n",
    "glove_path = os.path.join(\"..\", \"data\", \"glove.twitter.27B.100d.txt\")\n",
    "fasttext_path = os.path.join(\"..\", \"data\", \"crawl-300d-2M-subword.bin\")\n",
    "\n",
    "# Charger les embeddings GloVe\n",
    "glove_model = KeyedVectors.load_word2vec_format(glove_path, binary=False, no_header=True)\n",
    "\n",
    "# Charger les embeddings FastText (format Facebook binaire)\n",
    "fasttext_model = load_facebook_vectors(fasttext_path)\n"
   ],
   "id": "c125609d0b712d9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 6 : Création de la matrice d'embeddings",
   "id": "b03ac548e14b979d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_embedding_matrix(embedding_model, vocab, embedding_dim):\n",
    "    embedding_matrix = np.zeros((len(vocab) + 1, embedding_dim))\n",
    "    for word, i in vocab.items():\n",
    "        if word in embedding_model:\n",
    "            embedding_matrix[i] = embedding_model[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.zeros(embedding_dim)\n",
    "    return embedding_matrix\n"
   ],
   "id": "db1dc5660ba7ef35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 7 : Préparation des données pour l'entraînement",
   "id": "9e02d70fbfc593d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sous-échantillonnage pour réduire la charge de calcul à 0.1% pour tester rapidement le pipeline\n",
    "data = data.sample(frac=0.001, random_state=42)\n",
    "\n",
    "# Tokenisation des textes nettoyés\n",
    "num_words = 10000\n",
    "max_sequence_length = 100\n",
    "\n",
    "\n",
    "# Créer une couche TextVectorization\n",
    "tv_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=num_words,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_sequence_length\n",
    ")\n",
    "\n",
    "# Adapter TextVectorization sur les textes\n",
    "tv_layer.adapt(data['clean_text_embeddings'])\n",
    "\n",
    "# Convertir les textes en séquences\n",
    "X = tv_layer(data['clean_text_embeddings']).numpy()\n",
    "y = data['target'].values\n",
    "\n",
    "# Division des données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "a7ccec541e8a0d24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Nouvelle Cellule 8 : Création de la matrice d'embeddings pour GloVe",
   "id": "b07705ed805ef737"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Taille des vecteurs d'embeddings pour GloVe\n",
    "embedding_dim_glove = 100  # Assurez-vous que cette taille correspond à celle de votre fichier GloVe\n",
    "\n",
    "# Créer la matrice d'embeddings pour GloVe\n",
    "embedding_matrix_glove = create_embedding_matrix(glove_model, tv_layer.get_vocabulary(), embedding_dim_glove)\n",
    "\n",
    "# Vérifier la forme de la matrice d'embeddings pour s'assurer qu'elle est correctement initialisée\n",
    "print(f\"Shape of GloVe embedding matrix: {embedding_matrix_glove.shape}\")\n"
   ],
   "id": "b0116780a0a9e050"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Nouvelle Cellule 9 : Création de la matrice d'embeddings pour FastText",
   "id": "35378f973e6ea850"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Taille des vecteurs d'embeddings pour FastText\n",
    "embedding_dim_fasttext = 300  # Assurez-vous que cette taille correspond à celle de votre fichier FastText\n",
    "\n",
    "# Créer la matrice d'embeddings pour FastText\n",
    "embedding_matrix_fasttext = create_embedding_matrix(fasttext_model, tv_layer.get_vocabulary(), embedding_dim_fasttext)\n",
    "\n",
    "# Vérifier la forme de la matrice d'embeddings pour s'assurer qu'elle est correctement initialisée\n",
    "print(f\"Shape of FastText embedding matrix: {embedding_matrix_fasttext.shape}\")"
   ],
   "id": "5036b0ab97a6597"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 10 : Définition du modèle de deep learning",
   "id": "154bf2a3d9035516"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_model(embedding_matrix, input_length):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                                        output_dim=embedding_matrix.shape[1],\n",
    "                                        weights=[embedding_matrix],\n",
    "                                        input_length=input_length,\n",
    "                                        trainable=False))\n",
    "    model.add(tf.keras.layers.LSTM(128, return_sequences=False))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ],
   "id": "7ff6ff0c1a74fb2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 11 : Intégration du Grid Search avec early stopping   \n",
   "id": "cab78aff0a4cd848"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_model_for_search(embedding_matrix, input_length):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                                        output_dim=embedding_matrix.shape[1],\n",
    "                                        weights=[embedding_matrix],\n",
    "                                        input_length=input_length,\n",
    "                                        trainable=False))\n",
    "    model.add(tf.keras.layers.LSTM(128, return_sequences=False))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Paramètres à tester\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [5, 10]\n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Utiliser KerasClassifier pour intégrer le modèle dans scikit-learn\n",
    "model_glove_for_search = KerasClassifier(build_fn=lambda: build_model_for_search(embedding_matrix_glove, input_length=100))\n",
    "\n",
    "grid = GridSearchCV(estimator=model_glove_for_search, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Adapter le GridSearch sur les données\n",
    "grid_result = grid.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Afficher les meilleurs paramètres trouvés\n",
    "print(f\"Meilleurs hyperparamètres : {grid_result.best_params_}\")"
   ],
   "id": "3aee98af7e08b361"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 12 : Entraînement du modèle GloVe avec les meilleurs hyperparamètres",
   "id": "e18bc6c9352fd7f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Entraîner le modèle avec les meilleurs paramètres trouvés\n",
    "best_batch_size = grid_result.best_params_['batch_size']\n",
    "best_epochs = grid_result.best_params_['epochs']\n",
    "\n",
    "model_glove = build_model(embedding_matrix_glove, input_length=100)\n",
    "history_glove = model_glove.fit(X_train, y_train, epochs=best_epochs, batch_size=best_batch_size, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ],
   "id": "1b44301108784902"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 13 : Définition de la fonction evaluate_model",
   "id": "eeb746e808be3ec0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    # Prédictions du modèle\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Enregistrement des métriques dans MLFlow\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "    # Tracer la courbe ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for {model_name}')\n",
    "    roc_curve_path = f\"roc_curve_{model_name}.png\"\n",
    "    plt.savefig(roc_curve_path)\n",
    "    mlflow.log_artifact(roc_curve_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Model evaluation for {model_name} completed.\")\n"
   ],
   "id": "d076e0ce08a853a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 14 : Évaluation et enregistrement du modèle pour GloVe",
   "id": "f3814e4913568edf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "# Chemin absolu pour le dossier \"mlruns\"\n",
    "mlruns_path = Path(\"../mlruns\").resolve()\n",
    "\n",
    "# Vérifier que le dossier \"mlruns\" existe, sinon le créer\n",
    "if not mlruns_path.exists():\n",
    "    mlruns_path.mkdir(parents=True)\n",
    "\n",
    "# Vérifier que le sous-dossier \".trash\" existe, sinon le créer\n",
    "trash_folder = mlruns_path / \".trash\"\n",
    "if not trash_folder.exists():\n",
    "    trash_folder.mkdir(parents=True)\n",
    "\n",
    "# Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "mlflow.set_tracking_uri(mlruns_path.as_uri())\n",
    "\n",
    "# Créer ou utiliser l'expérience existante\n",
    "experiment_name = \"GloVe_Embedding_Experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Démarrer une nouvelle session MLFlow pour GloVe\n",
    "with mlflow.start_run(nested=True):\n",
    "    mlflow.log_param(\"embedding\", \"GloVe\")\n",
    "    mlflow.log_param(\"embedding_dim\", embedding_dim_glove)\n",
    "    mlflow.log_param(\"batch_size\", best_batch_size)\n",
    "    mlflow.log_param(\"epochs\", best_epochs)\n",
    "\n",
    "    # Évaluer le modèle et enregistrer les métriques et la courbe ROC\n",
    "    evaluate_model(model_glove, X_test, y_test, \"GloVe\")\n",
    "    mlflow.keras.log_model(model_glove, \"model_glove\")\n",
    "\n",
    "print(\"Modèle GloVe évalué et enregistré dans MLFlow.\")\n"
   ],
   "id": "4718ba675be78199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 15 : Grid Search pour le modèle FastText avec early stopping",
   "id": "1d677b4c3e1755c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Utiliser KerasClassifier pour intégrer le modèle FastText dans scikit-learn\n",
    "model_fasttext_for_search = KerasClassifier(build_fn=lambda: build_model_for_search(embedding_matrix_fasttext, input_length=100))\n",
    "\n",
    "# Définition des paramètres à tester pour FastText\n",
    "param_grid_fasttext = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [5, 10]\n",
    "}\n",
    "\n",
    "# Configurer le GridSearchCV pour le modèle FastText\n",
    "grid_fasttext = GridSearchCV(estimator=model_fasttext_for_search, param_grid=param_grid_fasttext, cv=3)\n",
    "\n",
    "# Adapter le GridSearch sur les données\n",
    "grid_result_fasttext = grid_fasttext.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Afficher les meilleurs paramètres trouvés pour FastText\n",
    "print(f\"Meilleurs hyperparamètres pour FastText : {grid_result_fasttext.best_params_}\")"
   ],
   "id": "90f4f9ecb4689377"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 16 : Entraînement du modèle FastText avec les meilleurs hyperparamètres",
   "id": "1b8b029e3b015ca6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_batch_size_fasttext = grid_result_fasttext.best_params_['batch_size']\n",
    "best_epochs_fasttext = grid_result_fasttext.best_params_['epochs']\n",
    "\n",
    "model_fasttext = build_model(embedding_matrix_fasttext, input_length=100)\n",
    "\n",
    "history_fasttext = model_fasttext.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=best_epochs_fasttext,\n",
    "    batch_size=best_batch_size_fasttext,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ],
   "id": "4e39d98871b70945"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cellule 17 : Évaluation et enregistrement du modèle FastText avec MLFlow",
   "id": "8198e90a2577d357"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "# Chemin absolu pour le dossier \"mlruns\"\n",
    "mlruns_path = Path(\"../mlruns\").resolve()\n",
    "\n",
    "# Vérifier que le dossier \"mlruns\" existe, sinon le créer\n",
    "if not mlruns_path.exists():\n",
    "    mlruns_path.mkdir(parents=True)\n",
    "\n",
    "# Vérifier que le sous-dossier \".trash\" existe, sinon le créer\n",
    "trash_folder = mlruns_path / \".trash\"\n",
    "if not trash_folder.exists():\n",
    "    trash_folder.mkdir(parents=True)\n",
    "\n",
    "# Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "mlflow.set_tracking_uri(mlruns_path.as_uri())\n",
    "\n",
    "# Créer ou utiliser l'expérience existante pour FastText\n",
    "experiment_name_fasttext = \"FastText_Embedding_Experiment\"\n",
    "mlflow.set_experiment(experiment_name_fasttext)\n",
    "\n",
    "# Démarrer une nouvelle session MLFlow pour FastText\n",
    "with mlflow.start_run(nested=True):\n",
    "    mlflow.log_param(\"embedding\", \"FastText\")\n",
    "    mlflow.log_param(\"embedding_dim\", embedding_dim_fasttext)\n",
    "    mlflow.log_param(\"batch_size\", best_batch_size_fasttext)\n",
    "    mlflow.log_param(\"epochs\", best_epochs_fasttext)\n",
    "\n",
    "    # Évaluer le modèle FastText et enregistrer les métriques et la courbe ROC\n",
    "    evaluate_model(model_fasttext, X_test, y_test, \"FastText\")\n",
    "    mlflow.keras.log_model(model_fasttext, \"model_fasttext\")\n",
    "\n",
    "print(\"Modèle FastText évalué et enregistré dans MLFlow.\")\n",
    "\n"
   ],
   "id": "3665223ce604da82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 18. Conclusion\n",
    "- Nous avons construit et entraîné des modèles de deep learning pour la classification de tweets en utilisant les embeddings GloVe et FastText.\n",
    "- Les performances des modèles ont été évaluées et enregistrées avec MLFlow.\n",
    "- Les hyperparamètres ont été optimisés avec Grid Search et Early Stopping contrairement au notebook précédent."
   ],
   "id": "b16bb58980ad2dee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
