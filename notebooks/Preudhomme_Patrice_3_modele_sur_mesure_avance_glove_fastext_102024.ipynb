{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Développement du \"Modèle sur mesure avancé\" avec des essais sur au moins deux word embeddings différents et en gardant celui qui permet d’obtenir les meilleures performances. Nous utiliserons Glove et FastText.\n",
    "-  Nous allons construire et entraîner un réseau de neurones pour chaque embedding, évaluer les performances et enregistrer les expérimentations avec MLFlow. \n",
    "-  C'est la colonne clean_text_embeddings qui sera utilisée pour les embeddings."
   ],
   "id": "e130531f31fb4315"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Charger le fichier CSV nettoyé",
   "id": "3d87f719c46eedd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:44.433675Z",
     "start_time": "2024-10-20T10:05:44.394861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verification version de tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "id": "e1c42060620514e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:58.043528Z",
     "start_time": "2024-10-20T10:05:44.534316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin relatif pour charger les données nettoyées\n",
    "file_path = os.path.join(\"..\", \"data\", \"cleaned_data_with_text_for_models.csv\")\n",
    "\n",
    "# Chargement du DataFrame nettoyé\n",
    "data = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# Vérification du contenu du DataFrame"
   ],
   "id": "32e4a3afe9437cba",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:58.312977Z",
     "start_time": "2024-10-20T10:05:58.125030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Réinitialiser l'index pour récupérer toutes les colonnes, y compris 'text' si elle est utilisée comme index\n",
    "data = data.reset_index()\n",
    "\n",
    "# Vérifier les colonnes disponibles après réinitialisation de l'index\n",
    "print(data.columns)\n"
   ],
   "id": "96b0d02836e331ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'clean_text_tfidf', 'clean_text_embeddings', 'clean_text_bert',\n",
      "       'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:58.747315Z",
     "start_time": "2024-10-20T10:05:58.346541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataframe info\n",
    "data.info()"
   ],
   "id": "93044ff2a6fbce5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count    Dtype \n",
      "---  ------                 --------------    ----- \n",
      " 0   text                   1600000 non-null  object\n",
      " 1   clean_text_tfidf       1592857 non-null  object\n",
      " 2   clean_text_embeddings  1596608 non-null  object\n",
      " 3   clean_text_bert        1600000 non-null  object\n",
      " 4   target                 1600000 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:59.057499Z",
     "start_time": "2024-10-20T10:05:58.773419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Valeurs manquantes\n",
    "print(data.isnull().sum())"
   ],
   "id": "57ece347a263b0a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                        0\n",
      "clean_text_tfidf         7143\n",
      "clean_text_embeddings    3392\n",
      "clean_text_bert             0\n",
      "target                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:59.171887Z",
     "start_time": "2024-10-20T10:05:59.088515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filtrer les lignes avec des valeurs manquantes dans la colonne 'clean_text_embeddings'\n",
    "missing_embeddings = data[data['clean_text_embeddings'].isnull()]\n",
    "\n",
    "# Afficher deux exemples pour analyser les raisons des valeurs manquantes\n",
    "print(missing_embeddings[['text', 'clean_text_tfidf', 'clean_text_embeddings']].head(2))"
   ],
   "id": "9cc762165073be07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             text clean_text_tfidf clean_text_embeddings\n",
      "208    @mandayyy               NaN                   NaN\n",
      "249  @mandayyy                 NaN                   NaN\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:59.556351Z",
     "start_time": "2024-10-20T10:05:59.201136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Supprimer les lignes avec des valeurs manquantes dans la colonne 'clean_text_embeddings'\n",
    "data = data.dropna(subset=['clean_text_embeddings'])\n"
   ],
   "id": "d2889fed2b6fe5dd",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:05:59.998890Z",
     "start_time": "2024-10-20T10:05:59.590846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vérifier les valeurs manquantes après suppression\n",
    "print(data.isnull().sum())"
   ],
   "id": "c5c4e5dafe121336",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                        0\n",
      "clean_text_tfidf         3751\n",
      "clean_text_embeddings       0\n",
      "clean_text_bert             0\n",
      "target                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Étape 1 : Charger les embeddings GloVe et FastText\n",
    "- Les liens pour télécharger les embeddings GloVe et FastText sont les suivants :\n",
    "- https://nlp.stanford.edu/projects/glove/\n",
    "- https://fasttext.cc/docs/en/english-vectors.html\n"
   ],
   "id": "3361dd5221253fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:09:27.842531Z",
     "start_time": "2024-10-20T10:06:00.036831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "\n",
    "# Chemin relatif pour charger les fichiers d'embeddings\n",
    "glove_path = os.path.join(\"..\", \"data\", \"glove.twitter.27B.100d.txt\")\n",
    "fasttext_path = os.path.join(\"..\", \"data\", \"crawl-300d-2M-subword.bin\")\n",
    "\n",
    "# Charger les embeddings GloVe\n",
    "glove_model = KeyedVectors.load_word2vec_format(glove_path, binary=False, no_header=True)\n",
    "\n",
    "# Charger les embeddings FastText (format Facebook binaire)\n",
    "fasttext_model = load_facebook_vectors(fasttext_path)\n"
   ],
   "id": "c2d83fbbca438645",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Étape 2 : Créer une fonction pour générer une matrice d'embeddings\n",
    "- Créer une matrice d'embeddings pour chaque modèle, basée sur le vocabulaire des données textuelles."
   ],
   "id": "dc8f14eccfeb1737"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:09:27.885143Z",
     "start_time": "2024-10-20T10:09:27.874720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fonction pour créer la matrice d'embeddings\n",
    "def create_embedding_matrix(embedding_model, vocab, embedding_dim):\n",
    "    embedding_matrix = np.zeros((len(vocab) + 1, embedding_dim))\n",
    "    for word, i in vocab.items():\n",
    "        if word in embedding_model:\n",
    "            embedding_matrix[i] = embedding_model[word]\n",
    "        else:\n",
    "            # Si le mot n'est pas trouvé dans les embeddings, laisser un vecteur de zéros\n",
    "            embedding_matrix[i] = np.zeros(embedding_dim)\n",
    "    return embedding_matrix\n"
   ],
   "id": "6e1bcc9f182aba0b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Étape 3 : Préparation des Données pour la vectorisation et la division en ensemble d'entrainement/test\n",
    "\n",
    "1. **Sous-échantillonnage des Données**\n",
    "2. **Définition des Paramètres de Tokenisation**\n",
    "3. **Application de `TextVectorization`**\n",
    "4. **Conversion des Textes en Séquences Numériques**\n",
    "5. **Préparation des Labels**\n",
    "6. **Division des Données en Ensemble d’Entraînement et de Test**"
   ],
   "id": "2c8665aac5a2fccf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:09:53.654053Z",
     "start_time": "2024-10-20T10:09:28.000996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# # Sous-échantillonnage des données à 0.1 % pour tester rapidement le pipeline\n",
    "data_sample = data.sample(frac=0.001, random_state=42)\n",
    "\n",
    "# Tokenisation des textes nettoyés pour les word embeddings\n",
    "num_words = 10000\n",
    "max_sequence_length = 100\n",
    "\n",
    "# Utiliser TextVectorization pour transformer les textes\n",
    "tv_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=num_words,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_sequence_length\n",
    ")\n",
    "\n",
    "# Adapter TextVectorization sur les textes\n",
    "tv_layer.adapt(data['clean_text_embeddings'])\n",
    "\n",
    "# Convertir les textes en séquences\n",
    "X = tv_layer(data['clean_text_embeddings'])\n",
    "\n",
    "# Convertir le Tensor en tableau NumPy\n",
    "X = X.numpy()\n",
    "\n",
    "# Préparer les labels\n",
    "y = data['target'].values  # Assurez-vous que y est également un tableau NumPy\n",
    "\n",
    "# Division des données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "486307e6877516e0",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Etape 5. Créer et entraîner les modèles avec GloVe et FastText\n",
    "- Nous allons maintenant construire et entraîner les modèles avec les embeddings GloVe et FastText."
   ],
   "id": "2d17ebed06bbc8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- a) Construction du Modèle de Réseau de Neurones avec Embeddings Pré-entraînés :",
   "id": "4b61145740c0e51a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:09:54.046831Z",
     "start_time": "2024-10-20T10:09:54.037434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Utilisation de tf.keras pour construire le modèle\n",
    "def build_model(embedding_matrix, input_length):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                                        output_dim=embedding_matrix.shape[1],\n",
    "                                        weights=[embedding_matrix],\n",
    "                                        input_length=input_length,\n",
    "                                        trainable=False))  # Ne pas entraîner les embeddings\n",
    "    model.add(tf.keras.layers.LSTM(128, return_sequences=False))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Classification binaire\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ],
   "id": "19e582192f197d04",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- b) Entraînement du modèle avec GloVe :",
   "id": "712343f52d045a52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Créer la matrice d'embeddings pour GloVe\n",
    "def create_embedding_matrix(glove_model, tv_layer, embedding_dim):\n",
    "    # Récupérer l'index des mots de TextVectorization\n",
    "    word_index = {word: index for index, word in enumerate(tv_layer.get_vocabulary())}\n",
    "    \n",
    "    # Initialiser la matrice d'embeddings\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if word in glove_model:\n",
    "            embedding_vector = glove_model[word]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "# Définir le nombre de mots et la longueur maximale des séquences\n",
    "num_words = 10000\n",
    "max_sequence_length = 100\n",
    "\n",
    "# Initialiser la couche TextVectorization\n",
    "tv_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=num_words,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_sequence_length\n",
    ")\n",
    "\n",
    "# Adapter TextVectorization sur les textes nettoyés\n",
    "tv_layer.adapt(data['clean_text_embeddings'])"
   ],
   "id": "50e4999f9be26bcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Définir la dimension des embeddings pour GloVe\n",
    "embedding_dim_glove = 100  # Taille des vecteurs d'embeddings pour GloVe, ajustez selon le modèle GloVe utilisé\n",
    "\n",
    "# Créer la matrice d'embeddings en utilisant TextVectorization (tv_layer)\n",
    "embedding_matrix_glove = create_embedding_matrix(glove_model, tv_layer, embedding_dim_glove)\n",
    "\n",
    "# Construire le modèle avec GloVe\n",
    "model_glove = build_model(embedding_matrix_glove, input_length=max_sequence_length)\n",
    "\n",
    "# Définir un callback pour sauvegarder le meilleur modèle en fonction de la perte de validation\n",
    "checkpoint_cb = ModelCheckpoint('best_model_glove.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Définir un callback pour arrêter l'entraînement si la perte de validation ne s'améliore pas après 3 époques\n",
    "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Créer une liste de callbacks pour le modèle\n",
    "callbacks = [checkpoint_cb, early_stopping_cb]\n",
    "\n",
    "# Entraîner le modèle avec les callbacks\n",
    "history_glove = model_glove.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=20,  # Augmenter le nombre d'époques pour permettre un entraînement suffisant avec early stopping\n",
    "    batch_size=32, \n",
    "    validation_data=(X_test, y_test), \n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Récupérer la meilleure époque atteinte\n",
    "best_epoch_glove = early_stopping_cb.stopped_epoch - early_stopping_cb.patience + 1 if early_stopping_cb.stopped_epoch else 20\n",
    "print(f\"La meilleure époque pour GloVe est : {best_epoch_glove}\")\n",
    "\n",
    "# Enregistrer la meilleure époque et le batch_size pour GloVe\n",
    "best_batch_size_glove = 32  # Celui que vous avez utilisé pour l'entraînement\n",
    "best_epochs_glove = best_epoch_glove"
   ],
   "id": "77a0387652be29fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- c) Entraînement du modèle avec FastText :",
   "id": "fcaf924a4ee54405"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Créer la matrice d'embeddings pour FastText\n",
    "def create_embedding_matrix(fasttext_model, tv_layer, embedding_dim):\n",
    "    # Récupérer l'index des mots de TextVectorization\n",
    "    word_index = {word: index for index, word in enumerate(tv_layer.get_vocabulary())}\n",
    "    \n",
    "    # Initialiser la matrice d'embeddings\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if word in fasttext_model:\n",
    "            embedding_vector = fasttext_model[word]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "# Définir le nombre de mots et la longueur maximale des séquences\n",
    "num_words = 10000\n",
    "max_sequence_length = 100\n",
    "\n",
    "# Initialiser la couche TextVectorization\n",
    "tv_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=num_words,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_sequence_length\n",
    ")\n",
    "\n",
    "# Adapter TextVectorization sur les textes nettoyés\n",
    "tv_layer.adapt(data['clean_text_embeddings'])\n"
   ],
   "id": "9ed0385b946a3565"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Définir la dimension des embeddings pour FastText\n",
    "embedding_dim_fasttext = 300  # Assurez-vous que cela correspond à la dimension de vos vecteurs FastText\n",
    "\n",
    "# Créer la matrice d'embeddings en utilisant TextVectorization (tv_layer)\n",
    "embedding_matrix_fasttext = create_embedding_matrix(fasttext_model, tv_layer, embedding_dim_fasttext)\n",
    "\n",
    "# Construire le modèle avec FastText\n",
    "model_fasttext = build_model(embedding_matrix_fasttext, input_length=max_sequence_length)\n",
    "\n",
    "# Définir un callback pour sauvegarder le meilleur modèle en fonction de la perte de validation\n",
    "checkpoint_cb = ModelCheckpoint('best_model_fasttext.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Définir un callback pour arrêter l'entraînement si la perte de validation ne s'améliore pas après 3 époques\n",
    "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Créer une liste de callbacks pour le modèle\n",
    "callbacks = [checkpoint_cb, early_stopping_cb]\n",
    "\n",
    "# Entraîner le modèle avec les callbacks\n",
    "history_fasttext = model_fasttext.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,  # Augmenter le nombre d'époques pour permettre un entraînement suffisant avec early stopping\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n",
    "# Récupérer la meilleure époque atteinte\n",
    "best_epoch_fasttext = early_stopping_cb.stopped_epoch - early_stopping_cb.patience + 1 if early_stopping_cb.stopped_epoch else 20\n",
    "print(f\"La meilleure époque pour FastText est : {best_epoch_fasttext}\")\n",
    "\n",
    "# Enregistrer les paramètres optimaux\n",
    "best_batch_size_fasttext = 32  # Celui que vous avez utilisé\n",
    "best_epochs_fasttext = best_epoch_fasttext\n",
    "\n"
   ],
   "id": "bbdbbdd34590552"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Définition de la fonction evaluate_model pour évaluer les performances des modèles :",
   "id": "8fbb42da3c94c580"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Vérifier l'initialisation de MLFlow",
   "id": "b0075d9e232a4a49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "# Définir l'expérience MLFlow\n",
    "mlflow.set_experiment(\"text_classification_experiment\")"
   ],
   "id": "7113e3dd667b3b3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Fonction pour évaluer les performances du modèle :",
   "id": "6875e3409e2a45f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    # Prédictions du modèle\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Enregistrement des métriques dans MLFlow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # Tracer la courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, marker='.')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve for {model_name}')\n",
    "        roc_curve_path = f\"roc_curve_{model_name}.png\"\n",
    "        plt.savefig(roc_curve_path)\n",
    "        mlflow.log_artifact(roc_curve_path)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Model evaluation for {model_name} completed.\")\n"
   ],
   "id": "53ff08b1bcfab0c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. Enregistrer les expérimentations avec MLFlow",
   "id": "5959befa2aba5fea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- a) Enregistrer les résultats pour GloVe :",
   "id": "4d0ca53f71068834"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "# Chemin absolu pour le dossier \"mlruns\"\n",
    "mlruns_path = Path(\"../mlruns\").resolve()\n",
    "\n",
    "# Vérifier que le dossier \"mlruns\" existe, sinon le créer\n",
    "if not mlruns_path.exists():\n",
    "    mlruns_path.mkdir(parents=True)\n",
    "\n",
    "# Vérifier que le sous-dossier \".trash\" existe, sinon le créer\n",
    "trash_folder = mlruns_path / \".trash\"\n",
    "if not trash_folder.exists():\n",
    "    trash_folder.mkdir(parents=True)\n",
    "\n",
    "# Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "mlflow.set_tracking_uri(mlruns_path.as_uri())\n",
    "\n",
    "# Définir le nom de l'expérience\n",
    "experiment_name = \"GloVe_Embedding_Experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Démarrer une nouvelle session MLFlow pour GloVe\n",
    "with mlflow.start_run(run_name=\"GloVe_Model_Evaluation\", nested=True) as run:\n",
    "    # Enregistrer les paramètres du modèle\n",
    "    mlflow.log_param(\"embedding\", \"GloVe\")\n",
    "    mlflow.log_param(\"embedding_dim\", embedding_dim_glove)\n",
    "    mlflow.log_param(\"batch_size\", best_batch_size_glove)\n",
    "    mlflow.log_param(\"epochs\", best_epochs_glove)\n",
    "\n",
    "    # Évaluer le modèle et enregistrer les métriques et la courbe ROC\n",
    "    evaluate_model(model_glove, X_test, y_test, \"GloVe\")\n",
    "\n",
    "    # Enregistrer le modèle Keras avec MLFlow\n",
    "    mlflow.keras.log_model(model_glove, \"glove_model\")\n",
    "\n",
    "    # Ajouter des informations sur le run\n",
    "    mlflow.log_artifact(mlruns_path)\n",
    "    mlflow.log_param(\"model_path\", \"glove_model\")\n",
    "    mlflow.log_param(\"experiment_id\", run.info.experiment_id)\n",
    "    mlflow.log_param(\"run_id\", run.info.run_id)\n",
    "\n",
    "print(\"Modèle GloVe évalué et enregistré dans MLFlow.\")\n"
   ],
   "id": "ceb262c86ca6ab20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- b) Enregistrer les résultats pour FastText :",
   "id": "8cb066147e80c96b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "# Chemin absolu pour le dossier \"mlruns\"\n",
    "mlruns_path = Path(\"../mlruns\").resolve()\n",
    "\n",
    "# Vérifier que le dossier \"mlruns\" existe, sinon le créer\n",
    "if not mlruns_path.exists():\n",
    "    mlruns_path.mkdir(parents=True)\n",
    "\n",
    "# Vérifier que le sous-dossier \".trash\" existe, sinon le créer\n",
    "trash_folder = mlruns_path / \".trash\"\n",
    "if not trash_folder.exists():\n",
    "    trash_folder.mkdir(parents=True)\n",
    "\n",
    "# Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "mlflow.set_tracking_uri(mlruns_path.as_uri())\n",
    "\n",
    "# Définir le nom de l'expérience\n",
    "experiment_name = \"FastText_Embedding_Experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Démarrer une nouvelle session MLFlow pour FastText\n",
    "with mlflow.start_run(run_name=\"FastText_Model_Evaluation\", nested=True) as run:\n",
    "    # Enregistrer les paramètres du modèle\n",
    "    mlflow.log_param(\"embedding\", \"FastText\")\n",
    "    mlflow.log_param(\"embedding_dim\", embedding_dim_fasttext)\n",
    "    mlflow.log_param(\"batch_size\", best_batch_size_fasttext)\n",
    "    mlflow.log_param(\"epochs\", best_epochs_fasttext)\n",
    "\n",
    "    # Évaluer le modèle et enregistrer les métriques et la courbe ROC\n",
    "    evaluate_model(model_fasttext, X_test, y_test, \"FastText\")\n",
    "\n",
    "    # Enregistrer le modèle Keras avec MLFlow\n",
    "    mlflow.keras.log_model(model_fasttext, \"fasttext_model\")\n",
    "\n",
    "    # Ajouter des informations sur le run\n",
    "    mlflow.log_artifact(mlruns_path)\n",
    "    mlflow.log_param(\"model_path\", \"fasttext_model\")\n",
    "    mlflow.log_param(\"experiment_id\", run.info.experiment_id)\n",
    "    mlflow.log_param(\"run_id\", run.info.run_id)\n",
    "\n",
    "print(\"Modèle FastText évalué et enregistré dans MLFlow.\")\n"
   ],
   "id": "6dc281e2e2e2a4c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7. Conclusion\n",
    "- Ce code utilise le fichier cleaned_data_with_text_for_models.csv et applique les word embeddings GloVe et FastText. Nous avons modifié le code pour utiliser les textes déjà nettoyés dans la colonne clean_text_embeddings. Après avoir entraîné les modèles, nous enregistrons les résultats et les modèles dans MLFlow afin de comparer les performances des deux embeddings et de sélectionner le meilleur."
   ],
   "id": "b16bb58980ad2dee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
