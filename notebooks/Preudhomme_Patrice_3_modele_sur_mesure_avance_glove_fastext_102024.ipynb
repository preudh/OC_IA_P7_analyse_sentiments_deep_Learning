{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Développement du \"Modèle sur mesure avancé\" avec des essais sur au moins deux word embeddings différents et en gardant celui qui permet d’obtenir les meilleures performances. Nous utiliserons Glove et FastText.\n",
    "-  Nous allons construire et entraîner un réseau de neurones pour chaque embedding, évaluer les performances et enregistrer les expérimentations avec MLFlow. \n",
    "-  C'est la colonne clean_text_embeddings qui sera utilisée pour les embeddings."
   ],
   "id": "e130531f31fb4315"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Charger le fichier CSV nettoyé",
   "id": "3d87f719c46eedd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:20:18.596428Z",
     "start_time": "2024-10-20T07:20:09.354753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verification version de tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "id": "e1c42060620514e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:20:27.852931Z",
     "start_time": "2024-10-20T07:20:18.614946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin relatif pour charger les données nettoyées\n",
    "file_path = os.path.join(\"..\", \"data\", \"cleaned_data_with_text_for_models.csv\")\n",
    "\n",
    "# Chargement du DataFrame nettoyé\n",
    "data = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# Vérification du contenu du DataFrame"
   ],
   "id": "32e4a3afe9437cba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:20:28.265620Z",
     "start_time": "2024-10-20T07:20:28.135174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Réinitialiser l'index pour récupérer toutes les colonnes, y compris 'text' si elle est utilisée comme index\n",
    "data = data.reset_index()\n",
    "\n",
    "# Vérifier les colonnes disponibles après réinitialisation de l'index\n",
    "print(data.columns)\n"
   ],
   "id": "96b0d02836e331ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'clean_text_tfidf', 'clean_text_embeddings', 'clean_text_bert',\n",
      "       'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:20:28.534008Z",
     "start_time": "2024-10-20T07:20:28.278039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataframe info\n",
    "data.info()"
   ],
   "id": "93044ff2a6fbce5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count    Dtype \n",
      "---  ------                 --------------    ----- \n",
      " 0   text                   1600000 non-null  object\n",
      " 1   clean_text_tfidf       1592857 non-null  object\n",
      " 2   clean_text_embeddings  1596608 non-null  object\n",
      " 3   clean_text_bert        1600000 non-null  object\n",
      " 4   target                 1600000 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:20:28.793735Z",
     "start_time": "2024-10-20T07:20:28.547110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Valeurs manquantes\n",
    "print(data.isnull().sum())"
   ],
   "id": "57ece347a263b0a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                        0\n",
      "clean_text_tfidf         7143\n",
      "clean_text_embeddings    3392\n",
      "clean_text_bert             0\n",
      "target                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:20:28.866571Z",
     "start_time": "2024-10-20T07:20:28.807787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filtrer les lignes avec des valeurs manquantes dans la colonne 'clean_text_embeddings'\n",
    "missing_embeddings = data[data['clean_text_embeddings'].isnull()]\n",
    "\n",
    "# Afficher deux exemples pour analyser les raisons des valeurs manquantes\n",
    "print(missing_embeddings[['text', 'clean_text_tfidf', 'clean_text_embeddings']].head(2))"
   ],
   "id": "9cc762165073be07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             text clean_text_tfidf clean_text_embeddings\n",
      "208    @mandayyy               NaN                   NaN\n",
      "249  @mandayyy                 NaN                   NaN\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:20:29.130340Z",
     "start_time": "2024-10-20T07:20:28.881604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Supprimer les lignes avec des valeurs manquantes dans la colonne 'clean_text_embeddings'\n",
    "data = data.dropna(subset=['clean_text_embeddings'])\n"
   ],
   "id": "d2889fed2b6fe5dd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:20:29.382975Z",
     "start_time": "2024-10-20T07:20:29.144027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vérifier les valeurs manquantes après suppression\n",
    "print(data.isnull().sum())"
   ],
   "id": "c5c4e5dafe121336",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                        0\n",
      "clean_text_tfidf         3751\n",
      "clean_text_embeddings       0\n",
      "clean_text_bert             0\n",
      "target                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Étape 1 : Charger les embeddings GloVe et FastText\n",
    "- Les liens pour télécharger les embeddings GloVe et FastText sont les suivants :\n",
    "- https://nlp.stanford.edu/projects/glove/\n",
    "- https://fasttext.cc/docs/en/english-vectors.html\n"
   ],
   "id": "3361dd5221253fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:23:22.297928Z",
     "start_time": "2024-10-20T07:20:29.395937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "\n",
    "# Chemin relatif pour charger les fichiers d'embeddings\n",
    "glove_path = os.path.join(\"..\", \"data\", \"glove.twitter.27B.100d.txt\")\n",
    "fasttext_path = os.path.join(\"..\", \"data\", \"crawl-300d-2M-subword.bin\")\n",
    "\n",
    "# Charger les embeddings GloVe\n",
    "glove_model = KeyedVectors.load_word2vec_format(glove_path, binary=False, no_header=True)\n",
    "\n",
    "# Charger les embeddings FastText (format Facebook binaire)\n",
    "fasttext_model = load_facebook_vectors(fasttext_path)\n"
   ],
   "id": "c2d83fbbca438645",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Étape 2 : Créer une fonction pour générer une matrice d'embeddings\n",
    "- Créer une matrice d'embeddings pour chaque modèle, basée sur le vocabulaire des données textuelles."
   ],
   "id": "dc8f14eccfeb1737"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:23:22.320068Z",
     "start_time": "2024-10-20T07:23:22.313466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fonction pour créer la matrice d'embeddings\n",
    "def create_embedding_matrix(embedding_model, vocab, embedding_dim):\n",
    "    embedding_matrix = np.zeros((len(vocab) + 1, embedding_dim))\n",
    "    for word, i in vocab.items():\n",
    "        if word in embedding_model:\n",
    "            embedding_matrix[i] = embedding_model[word]\n",
    "        else:\n",
    "            # Si le mot n'est pas trouvé dans les embeddings, laisser un vecteur de zéros\n",
    "            embedding_matrix[i] = np.zeros(embedding_dim)\n",
    "    return embedding_matrix\n"
   ],
   "id": "6e1bcc9f182aba0b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Étape 3 : Préparer le tokenizer et les données\n",
    "- Avant de créer le réseau de neurones, nous devons tokeniser le texte et préparer les données."
   ],
   "id": "51b84190262530be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:23:42.230245Z",
     "start_time": "2024-10-20T07:23:22.419153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Tokenisation des textes nettoyés pour les word embeddings\n",
    "num_words = 10000\n",
    "max_sequence_length = 100\n",
    "\n",
    "# Utiliser TextVectorization pour transformer les textes\n",
    "tv_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=num_words,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_sequence_length\n",
    ")\n",
    "\n",
    "# Adapter TextVectorization sur les textes\n",
    "tv_layer.adapt(data['clean_text_embeddings'])\n",
    "\n",
    "# Convertir les textes en séquences\n",
    "X = tv_layer(data['clean_text_embeddings'])\n",
    "\n",
    "# Convertir le Tensor en tableau NumPy\n",
    "X = X.numpy()\n",
    "\n",
    "# Préparer les labels\n",
    "y = data['target'].values  # Assurez-vous que y est également un tableau NumPy\n",
    "\n",
    "# Division des données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "486307e6877516e0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Cellule countvectorizer pour les embeddings GloVe et FastText (transformer les textes en vecteurs)\n",
    "- Nous utiliserons les textes déjà nettoyés pour les word embeddings à partir de la colonne clean_text_embeddings."
   ],
   "id": "e56cb41d2ce94229"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:23:42.644404Z",
     "start_time": "2024-10-20T07:23:42.252676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "# Sous-échantillonnage des données à 1 % pour tester rapidement le pipeline\n",
    "data_sample = data.sample(frac=0.001, random_state=42)\n",
    "\n",
    "# Utiliser CountVectorizer pour transformer les textes\n",
    "num_words = 10000\n",
    "vectorizer = CountVectorizer(max_features=num_words)\n",
    "\n",
    "# Adapter et transformer les textes\n",
    "X = vectorizer.fit_transform(data_sample['clean_text_embeddings'])\n",
    "\n",
    "# Padding manuel des séquences pour une longueur maximale de 100\n",
    "X_padded = hstack([X, np.zeros((X.shape[0], max(0, 100 - X.shape[1])))]).A\n",
    "\n",
    "# Préparer les labels\n",
    "y = data_sample['target'].values\n",
    "\n",
    "# Division des données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "8f7c6fb6cad37823",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Créer et entraîner les modèles avec GloVe et FastText\n",
    "- Nous allons maintenant construire et entraîner les modèles avec les embeddings GloVe et FastText."
   ],
   "id": "2d17ebed06bbc8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- a) Modèle de réseau de neurones :",
   "id": "4b61145740c0e51a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:23:42.682937Z",
     "start_time": "2024-10-20T07:23:42.674789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Utilisation de tf.keras pour construire le modèle\n",
    "def build_model(embedding_matrix, input_length):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                                        output_dim=embedding_matrix.shape[1],\n",
    "                                        weights=[embedding_matrix],\n",
    "                                        input_length=input_length,\n",
    "                                        trainable=False))  # Ne pas entraîner les embeddings\n",
    "    model.add(tf.keras.layers.LSTM(128, return_sequences=False))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Classification binaire\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ],
   "id": "19e582192f197d04",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- b) Entraînement du modèle avec GloVe :",
   "id": "712343f52d045a52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:23:42.774729Z",
     "start_time": "2024-10-20T07:23:42.717426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Créer la matrice d'embeddings pour GloVe\n",
    "def create_embedding_matrix(glove_model, word_index, embedding_dim):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if word in glove_model:\n",
    "            embedding_vector = glove_model[word]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "# Créer un tokenizer et l'ajuster sur les textes originaux\n",
    "# Remplacez 'data_sample' par le DataFrame qui contient vos données textuelles\n",
    "num_words = 10000  # Assurez-vous que ce nombre correspond à vos besoins\n",
    "texts = data_sample['clean_text_embeddings']\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(texts)"
   ],
   "id": "12e2425d8b9e8fcf",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:32:20.152738Z",
     "start_time": "2024-10-20T07:23:42.812378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Créer la matrice d'embeddings pour GloVe\n",
    "embedding_dim_glove = 100  # Taille des vecteurs d'embeddings pour GloVe\n",
    "embedding_matrix_glove = create_embedding_matrix(glove_model, tokenizer.word_index, embedding_dim_glove)\n",
    "\n",
    "# Construire et entraîner le modèle avec GloVe\n",
    "model_glove = build_model(embedding_matrix_glove, input_length=100)\n",
    "history_glove = model_glove.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n"
   ],
   "id": "a8017b3b69012c59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m108s\u001B[0m 3s/step - accuracy: 0.5160 - loss: 0.6901 - val_accuracy: 0.5344 - val_loss: 0.6917\n",
      "Epoch 2/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m98s\u001B[0m 2s/step - accuracy: 0.5555 - loss: 0.6868 - val_accuracy: 0.5312 - val_loss: 0.6901\n",
      "Epoch 3/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m98s\u001B[0m 2s/step - accuracy: 0.5279 - loss: 0.6862 - val_accuracy: 0.5312 - val_loss: 0.6889\n",
      "Epoch 4/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m108s\u001B[0m 3s/step - accuracy: 0.5561 - loss: 0.6838 - val_accuracy: 0.5219 - val_loss: 0.6907\n",
      "Epoch 5/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m105s\u001B[0m 3s/step - accuracy: 0.5471 - loss: 0.6824 - val_accuracy: 0.5125 - val_loss: 0.6904\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- c) Entraînement du modèle avec FastText :",
   "id": "fcaf924a4ee54405"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:41:23.127078Z",
     "start_time": "2024-10-20T07:32:20.185304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Créer la matrice d'embeddings pour FastText\n",
    "embedding_dim_fasttext = 300  # Taille des vecteurs d'embeddings pour FastText\n",
    "embedding_matrix_fasttext = create_embedding_matrix(fasttext_model, tokenizer.word_index, embedding_dim_fasttext)\n",
    "\n",
    "# Construire et entraîner le modèle avec FastText\n",
    "input_length = 100  # La longueur des séquences padding\n",
    "model_fasttext = build_model(embedding_matrix_fasttext, input_length=input_length)\n",
    "\n",
    "# Entraîner le modèle\n",
    "history_fasttext = model_fasttext.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n"
   ],
   "id": "30e4eec24174213b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pat\\.conda\\envs\\P7te\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m113s\u001B[0m 3s/step - accuracy: 0.5256 - loss: 0.6908 - val_accuracy: 0.4719 - val_loss: 0.6948\n",
      "Epoch 2/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m102s\u001B[0m 3s/step - accuracy: 0.4973 - loss: 0.6922 - val_accuracy: 0.5031 - val_loss: 0.6959\n",
      "Epoch 3/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m107s\u001B[0m 3s/step - accuracy: 0.5529 - loss: 0.6782 - val_accuracy: 0.5031 - val_loss: 0.6921\n",
      "Epoch 4/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m108s\u001B[0m 3s/step - accuracy: 0.5401 - loss: 0.6848 - val_accuracy: 0.5188 - val_loss: 0.7052\n",
      "Epoch 5/5\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m113s\u001B[0m 3s/step - accuracy: 0.5280 - loss: 0.6919 - val_accuracy: 0.5281 - val_loss: 0.6930\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. Enregistrer les expérimentations avec MLFlow",
   "id": "5959befa2aba5fea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- a) Enregistrer les résultats pour GloVe :",
   "id": "fd4cb7ffd0e9f50a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "# Chemin absolu pour le dossier \"mlruns\"\n",
    "mlruns_path = Path(\"../mlruns\").resolve()\n",
    "\n",
    "# Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "mlflow.set_tracking_uri(mlruns_path.as_uri())\n",
    "\n",
    "# Créer une nouvelle expérience ou utiliser une existante\n",
    "experiment_name = \"GloVe_Embedding_Experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Démarrer une nouvelle session MLFlow pour GloVe\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"embedding\", \"GloVe\")\n",
    "    mlflow.log_param(\"embedding_dim\", embedding_dim_glove)\n",
    "    mlflow.log_metric(\"accuracy\", model_glove.evaluate(X_test, y_test)[1])\n",
    "    \n",
    "    # Enregistrer le modèle GloVe comme artefact\n",
    "    mlflow.keras.log_model(model_glove, \"model_glove\")\n",
    "\n",
    "print(f\"Modèle GloVe enregistré dans {mlruns_path}.\")\n"
   ],
   "id": "aa4a3c94492e7077"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:41:58.011943Z",
     "start_time": "2024-10-20T07:41:23.161369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import mlflow\n",
    "# import mlflow.keras\n",
    "# import os\n",
    "# \n",
    "# # Chemin relatif pour le dossier \"models\"\n",
    "# relative_models_path = os.path.join(\"..\", \"models\")\n",
    "# \n",
    "# # Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "# mlflow.set_tracking_uri(relative_models_path)\n",
    "# \n",
    "# # Créer une nouvelle expérience ou utiliser une existante\n",
    "# experiment_name = \"GloVe_Embedding_Experiment\"\n",
    "# mlflow.set_experiment(experiment_name)\n",
    "# \n",
    "# # Démarrer une nouvelle session MLFlow pour GloVe\n",
    "# with mlflow.start_run():\n",
    "#     mlflow.log_param(\"embedding\", \"GloVe\")\n",
    "#     mlflow.log_param(\"embedding_dim\", embedding_dim_glove)\n",
    "#     mlflow.log_metric(\"accuracy\", model_glove.evaluate(X_test, y_test)[1])\n",
    "#     \n",
    "#     # Enregistrer le modèle GloVe comme artefact\n",
    "#     mlflow.keras.log_model(model_glove, \"model_glove\")\n",
    "# \n",
    "# print(f\"Modèle GloVe enregistré dans {relative_models_path}.\")\n"
   ],
   "id": "d9edc5ee1c52c21a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 09:41:23 INFO mlflow.tracking.fluent: Experiment with name 'GloVe_Embedding_Experiment' does not exist. Creating a new experiment.\n",
      "2024/10/20 09:41:24 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 2s/step - accuracy: 0.5026 - loss: 0.6920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 09:41:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/20 09:41:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle GloVe enregistré dans ..\\models.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:41:58.038705Z",
     "start_time": "2024-10-20T07:41:58.034942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import mlflow\n",
    "# import mlflow.keras\n",
    "# \n",
    "# # Enregistrer les résultats pour GloVe\n",
    "# mlflow.start_run(run_name=\"GloVe Embedding\")\n",
    "# mlflow.log_param(\"embedding\", \"GloVe\")\n",
    "# mlflow.log_param(\"embedding_dim\", embedding_dim_glove)\n",
    "# mlflow.log_metric(\"accuracy\", model_glove.evaluate(X_test, y_test)[1])\n",
    "# mlflow.keras.log_model(model_glove, \"model_glove\")\n",
    "# mlflow.end_run()"
   ],
   "id": "e1ba51676026e25f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- b) Enregistrer les résultats pour FastText :",
   "id": "8cb066147e80c96b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "# Chemin absolu pour le dossier \"mlruns\" en utilisant pathlib\n",
    "mlruns_path = Path(\"../mlruns\").resolve()\n",
    "\n",
    "# Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "mlflow.set_tracking_uri(mlruns_path.as_uri())\n",
    "\n",
    "# Créer une nouvelle expérience ou utiliser une existante\n",
    "experiment_name = \"FastText_Embedding_Experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Démarrer une nouvelle session MLFlow pour FastText\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"embedding\", \"FastText\")\n",
    "    mlflow.log_param(\"embedding_dim\", embedding_dim_fasttext)\n",
    "    mlflow.log_metric(\"accuracy\", model_fasttext.evaluate(X_test, y_test)[1])\n",
    "    \n",
    "    # Enregistrer le modèle FastText comme artefact\n",
    "    mlflow.keras.log_model(model_fasttext, \"model_fasttext\")\n",
    "\n",
    "print(f\"Modèle FastText enregistré dans {mlruns_path}.\")\n"
   ],
   "id": "37815cdc3b40fd04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:42:19.839229Z",
     "start_time": "2024-10-20T07:41:58.062878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import mlflow\n",
    "# import mlflow.keras\n",
    "# import os\n",
    "# \n",
    "# # Chemin relatif pour le dossier \"models\"\n",
    "# relative_models_path = os.path.join(\"..\", \"models\")\n",
    "# \n",
    "# # Configuration du chemin pour stocker les artefacts de MLFlow\n",
    "# mlflow.set_tracking_uri(relative_models_path)\n",
    "# \n",
    "# # Créer une nouvelle expérience ou utiliser une existante\n",
    "# experiment_name = \"FastText_Embedding_Experiment\"\n",
    "# mlflow.set_experiment(experiment_name)\n",
    "# \n",
    "# # Démarrer une nouvelle session MLFlow pour FastText\n",
    "# with mlflow.start_run():\n",
    "#     mlflow.log_param(\"embedding\", \"FastText\")\n",
    "#     mlflow.log_param(\"embedding_dim\", embedding_dim_fasttext)\n",
    "#     mlflow.log_metric(\"accuracy\", model_fasttext.evaluate(X_test, y_test)[1])\n",
    "#     \n",
    "#     # Enregistrer le modèle FastText comme artefact\n",
    "#     mlflow.keras.log_model(model_fasttext, \"model_fasttext\")\n",
    "\n",
    "print(f\"Modèle FastText enregistré dans {relative_models_path}.\")\n"
   ],
   "id": "92a07a58a8a70e52",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 09:41:58 INFO mlflow.tracking.fluent: Experiment with name 'FastText_Embedding_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 1s/step - accuracy: 0.5180 - loss: 0.6924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 09:42:11 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/20 09:42:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle FastText enregistré dans ..\\models.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:42:19.865488Z",
     "start_time": "2024-10-20T07:42:19.861905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Enregistrer les résultats pour FastText\n",
    "# mlflow.start_run(run_name=\"FastText Embedding\")\n",
    "# mlflow.log_param(\"embedding\", \"FastText\")\n",
    "# mlflow.log_param(\"embedding_dim\", embedding_dim_fasttext)\n",
    "# mlflow.log_metric(\"accuracy\", model_fasttext.evaluate(X_test, y_test)[1])\n",
    "# mlflow.keras.log_model(model_fasttext, \"model_fasttext\")\n",
    "# mlflow.end_run()"
   ],
   "id": "7f2318068a21fc4b",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7. Conclusion\n",
    "- Ce code utilise le fichier cleaned_data_with_text_for_models.csv et applique les word embeddings GloVe et FastText. Nous avons modifié le code pour utiliser les textes déjà nettoyés dans la colonne clean_text_embeddings. Après avoir entraîné les modèles, nous enregistrons les résultats et les modèles dans MLFlow afin de comparer les performances des deux embeddings et de sélectionner le meilleur."
   ],
   "id": "b16bb58980ad2dee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
